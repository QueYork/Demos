{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce33bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c666ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPR, self).__init__()\n",
    "        self.W = None             # user matrix\n",
    "        self.H = None             # item matrix\n",
    "        self.Wsc = None           # scorer\n",
    "        self.Hsc = None \n",
    "        \n",
    "        self.uid = None\n",
    "        self.iid = None\n",
    "        \n",
    "        self.user_items = {}\n",
    "        self.dev_user_items = {}\n",
    "        \n",
    "        self.rating_exp = None   # softmax sum\n",
    "        self.rating_exp_mul_H = None\n",
    "    \n",
    "    def preprocess(self, df, train_size=0.8, test_size=0.1):\n",
    "        df = df.rename(columns = {df.columns[0]: 'ori_uid', df.columns[1]: 'ori_iid', df.columns[2]: 'rating'})\n",
    "        \n",
    "        uid_map = pd.DataFrame({\"ori_uid\": np.asarray(list(set(df.iloc[:,0].values)))})\n",
    "        uid_map[\"serial_uid\"] = uid_map.index\n",
    "        iid_map = pd.DataFrame({\"ori_iid\": np.asarray(list(set(df.iloc[:,1].values)))})\n",
    "        iid_map[\"serial_iid\"] = iid_map.index\n",
    "        \n",
    "        self.uid = uid_map[\"serial_uid\"].values\n",
    "        self.iid = iid_map[\"serial_iid\"].values\n",
    "        \n",
    "        df = df.merge(uid_map, left_on = 'ori_uid', right_on = 'ori_uid', how=\"left\")\n",
    "        df = df.merge(iid_map, left_on = 'ori_iid', right_on = 'ori_iid', how=\"left\")\n",
    "        df = df[['serial_uid', 'serial_iid', 'rating']]\n",
    "        \n",
    "        train, test = self._split(df, train_size)\n",
    "        test, dev = self._split(test, test_size / (1 - train_size))\n",
    "        return train, test, dev\n",
    "    \n",
    "    def _split(self, df, ratio):\n",
    "        train = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        test = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        for i in self.uid:\n",
    "            train_1, test_1 = train_test_split(df[df.iloc[:, 0] == i], train_size = ratio, shuffle = True, random_state = 5)\n",
    "            train = pd.concat([train, train_1])\n",
    "            test = pd.concat([test, test_1])\n",
    "        return train, test\n",
    "    \n",
    "    def generate_train_batch(self, batch, sets):\n",
    "        train = []\n",
    "        for b in range(batch):\n",
    "            u = self.uid[np.random.randint(0, len(self.uid))]\n",
    "            i = sets[u][np.random.randint(0, len(sets[u]))]\n",
    "            j = self.iid[np.random.randint(0, len(self.iid))]\n",
    "            while j in sets[u]:\n",
    "                j = self.iid[np.random.randint(0, len(self.iid))]\n",
    "            train.append([u, i, j])\n",
    "        return np.asarray(train) \n",
    "\n",
    "    def forward(self, uids, iids, device):\n",
    "        self.rating_exp = torch.zeros(len(self.uid)).to(device)\n",
    "        self.rating_exp_mul_H = torch.zeros([len(self.uid), self.H.shape[1]]).to(device)\n",
    "        \n",
    "        # 处理 idx 得到 embedded Wu Hi\n",
    "        emb_idxs = [self.user_items[uid] for uid in uids]\n",
    "        item_emb = nn.utils.rnn.pad_sequence([self.Hsc[emb_idx] for emb_idx in emb_idxs], batch_first=True)\n",
    "        user_emb = self.Wsc[uids][:, None, :]\n",
    "        \n",
    "        # 计算批次内 user_item 得分\n",
    "        user_item_exp_sc = torch.sum(item_emb * user_emb, dim = -1)\n",
    "        mask = (user_item_exp_sc != 0).type(torch.float32)\n",
    "        # 取指数， mask 保证补 0 位还是 0\n",
    "        user_item_exp_sc = torch.exp(user_item_exp_sc) * mask\n",
    "        \n",
    "        # 计算指数和\n",
    "        self.rating_exp_mul_H[uids] = torch.sum(user_item_exp_sc.unsqueeze(2).repeat(1, 1, self.H.shape[1]) * item_emb, dim = 1)\n",
    "        self.rating_exp[uids] = torch.sum(user_item_exp_sc, dim = 1)\n",
    "        #返回 softmax probablilty of item i among user_items\n",
    "        return torch.exp(torch.sum(self.Wsc[uids] * self.Hsc[iids], dim = 1)) / self.rating_exp[uids]\n",
    "            \n",
    "    def fit_dds(self, df, dev, k, stepsize=1, max_iter=10, batch=10000, dev_batch=5000):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        # 初始化 W，H\n",
    "        self.W = nn.Parameter(torch.rand(len(self.uid), k).to(device) * 0.01)   \n",
    "        self.H = nn.Parameter(torch.rand(len(self.iid), k).to(device) * 0.01) \n",
    "        \n",
    "        # 初始化 scorer\n",
    "        self.Wsc = torch.rand(len(self.uid), k).to(device) * 0.01    \n",
    "        self.Hsc = torch.rand(len(self.iid), k).to(device) * 0.01  \n",
    "        \n",
    "        # 创建字典：用户u对应他访问过的所有items集合    \n",
    "        self.user_items = df.groupby(df.columns[0])[df.columns[1]].apply(lambda x: np.array(x)).to_dict()\n",
    "        self.dev_user_items = dev.groupby(dev.columns[0])[dev.columns[1]].apply(lambda x: np.array(x)).to_dict()\n",
    "        \n",
    "        # 主模型优化器        \n",
    "        optimizer = optim.SGD([self.W, self.H], lr=stepsize)\n",
    "        \n",
    "        for x in range(max_iter):            \n",
    "            #取训练批次：uij三元组\n",
    "            uij = self.generate_train_batch(batch, self.user_items)\n",
    "            u = uij[:, 0]\n",
    "            i = uij[:, 1]\n",
    "            j = uij[:, 2]\n",
    "            u_emb = self.W[u]\n",
    "            i_emb = self.H[i]\n",
    "            j_emb = self.H[j]\n",
    "            \n",
    "            # 评分器概率分布，forward 返回 softmax 概率分布\n",
    "            score_prob = self.forward(u, i, device)     \n",
    "            \n",
    "            # 主模型参数更新\n",
    "            optimizer.zero_grad() \n",
    "            score_loss = -torch.sum(score_prob * torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb-j_emb),dim = 1))))\n",
    "            bpr_loss = -torch.mean(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
    "            score_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 训练集上 W,H 的梯度\n",
    "            W_grad_sum = self.W.grad.clone()\n",
    "            H_grad_sum = self.H.grad.clone()\n",
    "            \n",
    "            # 对数概率分布下 Wsc, Hsc 梯度\n",
    "            log_prob_Wsc_grad = torch.zeros((len(self.uid), k)).to(device)\n",
    "            log_prob_Hsc_grad = torch.zeros((len(self.iid), k)).to(device)\n",
    "            log_prob_Wsc_grad[u] = self.Hsc[i] - self.rating_exp_mul_H[u] / self.rating_exp[u].unsqueeze(1).repeat(1, k)\n",
    "            log_prob_Hsc_grad[i] = self.Wsc[u] * ((1 - score_prob).unsqueeze(1).repeat(1, k))\n",
    "            \n",
    "            #取 dev uij三元组\n",
    "            uij = self.generate_train_batch(dev_batch, self.dev_user_items)\n",
    "            u = uij[:, 0]\n",
    "            i = uij[:, 1]\n",
    "            j = uij[:, 2]\n",
    "            u_emb = self.W[u]\n",
    "            i_emb = self.H[i]\n",
    "            j_emb = self.H[j]\n",
    "            \n",
    "            # 计算 dev 集上 W,H 的梯度\n",
    "            optimizer.zero_grad()\n",
    "            dev_loss = -torch.sum(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
    "            dev_loss.backward()\n",
    "            W_grad_dev_sum = self.W.grad.clone()    \n",
    "            H_grad_dev_sum = self.H.grad.clone()\n",
    "\n",
    "            # 计算 reward: reward 为 W,H 在训练集和 dev 集上的梯度积    \n",
    "            r_W = torch.sum(W_grad_sum * W_grad_dev_sum, dim=1)\n",
    "            r_H = torch.sum(H_grad_sum * H_grad_dev_sum, dim=1)\n",
    "            r_W = r_W.unsqueeze(1).repeat(1, k)\n",
    "            r_H = r_H.unsqueeze(1).repeat(1, k)\n",
    "\n",
    "            # Wsc，Hsc 更新\n",
    "            self.Wsc += r_W * log_prob_Wsc_grad\n",
    "            self.Hsc += r_H * log_prob_Hsc_grad\n",
    "\n",
    "            if ( x + 1 ) % 10 == 0:\n",
    "                print(f\"Iteration: {x+1}, BPR loss: {bpr_loss.item()}\")\n",
    "    \n",
    "    def fit_ori(self, df, k, stepsize=0.05, max_iter=10, batch=10000):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        self.W = nn.Parameter(torch.rand(len(self.uid), k).to(device) * 0.01)    # 初始化 W，H\n",
    "        self.H = nn.Parameter(torch.rand(len(self.iid), k).to(device) * 0.01)  \n",
    "        \n",
    "        # 创建字典：用户u对应他访问过的所有items集合\n",
    "        self.user_items = df.groupby(df.columns[0])[df.columns[1]].apply(lambda x: np.array(x)).to_dict()\n",
    "        \n",
    "        optimizer = optim.SGD([self.W, self.H], lr=stepsize)     # 主模型优化器\n",
    "        for x in range(max_iter):\n",
    "            #取训练批次：uij三元组\n",
    "            uij = self.generate_train_batch(batch, self.user_items)\n",
    "            \n",
    "            u = uij[:, 0]\n",
    "            i = uij[:, 1]\n",
    "            j = uij[:, 2]\n",
    "            u_emb = self.W[u]\n",
    "            i_emb = self.H[i]\n",
    "            j_emb = self.H[j]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = -torch.sum(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if ( x + 1 ) % 10 == 0:\n",
    "                print(f\"Iteration: {x+1}, BPR loss: {loss.item() / batch}\")\n",
    "    \n",
    "    def _predict(self, uid, items, n):\n",
    "        scores = torch.mv(self.H[items], self.W[uid])\n",
    "        if n > scores.shape[0]: \n",
    "            n = scores.shape[0]\n",
    "        top_N_val, top_N_idx = torch.topk(scores, k=n)\n",
    "        return list(zip(items[top_N_idx.cpu()], top_N_val.cpu()))\n",
    "\n",
    "    def NDCG(self, uid, test, n):         # 用模型排序+真实分数计算 DCG, 重排后计算 iDCG\n",
    "        test_user = test[test.iloc[:, 0] == uid]\n",
    "        rating = self._predict(uid, test_user.iloc[:, 1].values, n)\n",
    "        irating =sorted(test_user.iloc[:, 2].values, reverse=True)\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        if n > len(irating): n = len(irating)  \n",
    "        for i in range(n):\n",
    "            r = test_user[test_user.iloc[:, 1]==rating[i][0]].iloc[0, 2]\n",
    "            dcg += 1.0 * (2**r - 1) / math.log(i + 2, 2)\n",
    "            idcg += 1.0 * (2**irating[i] - 1) / math.log(i + 2, 2)\n",
    "        return dcg / idcg\n",
    "\n",
    "    def performance(self, test, n):      # Output recall@n, precision@n, NDCG@n\n",
    "        hit = 0\n",
    "        n_recall = 0\n",
    "        n_precision = 0\n",
    "        ndcg = 0\n",
    "        for i in self.uid:\n",
    "            # Items that User i hasn't tried in training set\n",
    "            unknown_items = np.setdiff1d(self.iid, self.user_items[i])\n",
    "            # Items that User i actually tried in testing set\n",
    "            known_items = test[test.iloc[:, 0] == i].iloc[:, 1].values\n",
    "            \n",
    "            #目标：预测 unknown items 中的top_N，若击中test中的items，则为有效预测\n",
    "            ru = self._predict(i, unknown_items, n)\n",
    "            \n",
    "            hit += sum(1 for item, pui in ru if item in known_items)\n",
    "            n_recall += len(known_items)\n",
    "            n_precision += n\n",
    "            ndcg += self.NDCG(i, test, n)\n",
    "            \n",
    "        recall = hit / (1.0 * n_recall)\n",
    "        precision = hit / (1.0 * n_precision)\n",
    "        ndcg /= len(self.uid)\n",
    "        return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319ffcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./ml-100k/u.data\", sep=\"\\t\", names=['user id', 'item id', 'rating', 'timestamp'])\n",
    "df2 = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", names=['user id', 'item id', 'rating', 'timestamp'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2cdfb1",
   "metadata": {},
   "source": [
    "### 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1781ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79619, 3)\n",
      "(9942, 3)\n",
      "(10439, 3)\n"
     ]
    }
   ],
   "source": [
    "model1 = BPR()\n",
    "model2 = BPR()\n",
    "train1, test1, dev1 = model1.preprocess(df1)\n",
    "train2, test2, dev2 = model2.preprocess(df1)\n",
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(dev1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055d2a",
   "metadata": {},
   "source": [
    "### 100K Pure BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26dbdb06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.62378154296875\n",
      "Iteration: 20, BPR loss: 0.35774130859375\n",
      "Iteration: 30, BPR loss: 0.3063040283203125\n",
      "Iteration: 40, BPR loss: 0.305498193359375\n",
      "Iteration: 50, BPR loss: 0.29411689453125\n",
      "Iteration: 60, BPR loss: 0.2744450439453125\n",
      "Iteration: 70, BPR loss: 0.2479959716796875\n",
      "Iteration: 80, BPR loss: 0.214836279296875\n",
      "Iteration: 90, BPR loss: 0.2020580810546875\n",
      "Iteration: 100, BPR loss: 0.1797273193359375\n",
      "Iteration: 110, BPR loss: 0.16960958251953126\n",
      "Iteration: 120, BPR loss: 0.169327880859375\n",
      "Iteration: 130, BPR loss: 0.16193299560546875\n",
      "Iteration: 140, BPR loss: 0.15832347412109374\n",
      "Iteration: 150, BPR loss: 0.1492018310546875\n",
      "Iteration: 160, BPR loss: 0.1437028564453125\n",
      "Iteration: 170, BPR loss: 0.1342430908203125\n",
      "Iteration: 180, BPR loss: 0.13368096923828124\n",
      "Iteration: 190, BPR loss: 0.1286603515625\n",
      "Iteration: 200, BPR loss: 0.1243393798828125\n",
      "Iteration: 210, BPR loss: 0.11574803466796875\n",
      "Iteration: 220, BPR loss: 0.1156223388671875\n",
      "Iteration: 230, BPR loss: 0.11205457763671875\n",
      "Iteration: 240, BPR loss: 0.10206607666015625\n",
      "Iteration: 250, BPR loss: 0.105852880859375\n",
      "Iteration: 260, BPR loss: 0.09834216918945313\n",
      "Iteration: 270, BPR loss: 0.09370635986328125\n",
      "Iteration: 280, BPR loss: 0.099905859375\n",
      "Iteration: 290, BPR loss: 0.08891931762695313\n",
      "Iteration: 300, BPR loss: 0.085900146484375\n",
      "Iteration: 310, BPR loss: 0.0850247314453125\n",
      "Iteration: 320, BPR loss: 0.07927620849609375\n",
      "Iteration: 330, BPR loss: 0.08096522216796875\n",
      "Iteration: 340, BPR loss: 0.0734009521484375\n",
      "Iteration: 350, BPR loss: 0.07255601806640626\n",
      "Iteration: 360, BPR loss: 0.07532508544921875\n",
      "Iteration: 370, BPR loss: 0.06832603759765625\n",
      "Iteration: 380, BPR loss: 0.07180404052734375\n",
      "Iteration: 390, BPR loss: 0.06537581787109376\n",
      "Iteration: 400, BPR loss: 0.06991259765625\n",
      "Iteration: 410, BPR loss: 0.06455941162109376\n",
      "Iteration: 420, BPR loss: 0.06275291748046875\n",
      "Iteration: 430, BPR loss: 0.061233795166015625\n",
      "Iteration: 440, BPR loss: 0.0585128662109375\n",
      "Iteration: 450, BPR loss: 0.05757705078125\n",
      "Iteration: 460, BPR loss: 0.058621142578125\n",
      "Iteration: 470, BPR loss: 0.057211248779296876\n",
      "Iteration: 480, BPR loss: 0.054927716064453125\n",
      "Iteration: 490, BPR loss: 0.050742413330078125\n",
      "Iteration: 500, BPR loss: 0.056198919677734376\n",
      "CPU times: total: 1min 3s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit_ori(train1, k = 50, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85461f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.13870625662778366\n",
      "Recall@10: 0.1315630657815329\n",
      "NDCG@10: 0.8245452801685419\n",
      "CPU times: total: 3.03 s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "rec, pre, ndcg = model1.performance(test1, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f9423",
   "metadata": {},
   "source": [
    "### 100K BPR + Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd574457",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.665634274482727\n",
      "Iteration: 20, BPR loss: 0.5026760101318359\n",
      "Iteration: 30, BPR loss: 0.4225527346134186\n",
      "Iteration: 40, BPR loss: 0.3804778754711151\n",
      "Iteration: 50, BPR loss: 0.35433879494667053\n",
      "Iteration: 60, BPR loss: 0.33763349056243896\n",
      "Iteration: 70, BPR loss: 0.32537055015563965\n",
      "Iteration: 80, BPR loss: 0.3282545506954193\n",
      "Iteration: 90, BPR loss: 0.30993345379829407\n",
      "Iteration: 100, BPR loss: 0.3006282448768616\n",
      "Iteration: 110, BPR loss: 0.2878747582435608\n",
      "Iteration: 120, BPR loss: 0.2775033116340637\n",
      "Iteration: 130, BPR loss: 0.2510831356048584\n",
      "Iteration: 140, BPR loss: 0.2414250671863556\n",
      "Iteration: 150, BPR loss: 0.24074730277061462\n",
      "Iteration: 160, BPR loss: 0.21577690541744232\n",
      "Iteration: 170, BPR loss: 0.21319936215877533\n",
      "Iteration: 180, BPR loss: 0.2050953358411789\n",
      "Iteration: 190, BPR loss: 0.19327235221862793\n",
      "Iteration: 200, BPR loss: 0.18959447741508484\n",
      "Iteration: 210, BPR loss: 0.186885803937912\n",
      "Iteration: 220, BPR loss: 0.17993134260177612\n",
      "Iteration: 230, BPR loss: 0.17205710709095\n",
      "Iteration: 240, BPR loss: 0.17307348549365997\n",
      "Iteration: 250, BPR loss: 0.16325324773788452\n",
      "Iteration: 260, BPR loss: 0.16656559705734253\n",
      "Iteration: 270, BPR loss: 0.1623472422361374\n",
      "Iteration: 280, BPR loss: 0.15185971558094025\n",
      "Iteration: 290, BPR loss: 0.1565905660390854\n",
      "Iteration: 300, BPR loss: 0.15334948897361755\n",
      "Iteration: 310, BPR loss: 0.14840655028820038\n",
      "Iteration: 320, BPR loss: 0.14561283588409424\n",
      "Iteration: 330, BPR loss: 0.14114387333393097\n",
      "Iteration: 340, BPR loss: 0.13782057166099548\n",
      "Iteration: 350, BPR loss: 0.13911786675453186\n",
      "Iteration: 360, BPR loss: 0.1355895698070526\n",
      "Iteration: 370, BPR loss: 0.13615968823432922\n",
      "Iteration: 380, BPR loss: 0.13513785600662231\n",
      "Iteration: 390, BPR loss: 0.13050299882888794\n",
      "Iteration: 400, BPR loss: 0.12282619625329971\n",
      "Iteration: 410, BPR loss: 0.1260600984096527\n",
      "Iteration: 420, BPR loss: 0.12749916315078735\n",
      "Iteration: 430, BPR loss: 0.12735331058502197\n",
      "Iteration: 440, BPR loss: 0.1226629763841629\n",
      "Iteration: 450, BPR loss: 0.12324003875255585\n",
      "Iteration: 460, BPR loss: 0.11430154740810394\n",
      "Iteration: 470, BPR loss: 0.11291225254535675\n",
      "Iteration: 480, BPR loss: 0.11213965713977814\n",
      "Iteration: 490, BPR loss: 0.11525719612836838\n",
      "Iteration: 500, BPR loss: 0.12179797142744064\n",
      "CPU times: total: 1min 25s\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2.fit_dds(train1, dev1, k = 50, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b0edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.15906680805938495\n",
      "Recall@10: 0.15087507543753773\n",
      "NDCG@10: 0.8299234526856015\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "rec, pre, ndcg = model2.performance(test1, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c144c",
   "metadata": {},
   "source": [
    "### 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23925bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797758, 3)\n",
      "(99692, 3)\n",
      "(102759, 3)\n"
     ]
    }
   ],
   "source": [
    "model3 = BPR()\n",
    "model4 = BPR()\n",
    "train3, test3, dev3 = model3.preprocess(df2)\n",
    "train4, test4, dev4 = model4.preprocess(df2)\n",
    "print(train3.shape)\n",
    "print(test3.shape)\n",
    "print(dev3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88834487",
   "metadata": {},
   "source": [
    "### 1M Pure BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81b6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.6909599609375\n",
      "Iteration: 20, BPR loss: 0.676350341796875\n",
      "Iteration: 30, BPR loss: 0.6062896484375\n",
      "Iteration: 40, BPR loss: 0.49626005859375\n",
      "Iteration: 50, BPR loss: 0.4144986328125\n",
      "Iteration: 60, BPR loss: 0.370673193359375\n",
      "Iteration: 70, BPR loss: 0.348971142578125\n",
      "Iteration: 80, BPR loss: 0.33403466796875\n",
      "Iteration: 90, BPR loss: 0.33209560546875\n",
      "Iteration: 100, BPR loss: 0.331827880859375\n",
      "Iteration: 110, BPR loss: 0.3192904296875\n",
      "Iteration: 120, BPR loss: 0.323548046875\n",
      "Iteration: 130, BPR loss: 0.3217059814453125\n",
      "Iteration: 140, BPR loss: 0.317639990234375\n",
      "Iteration: 150, BPR loss: 0.324446337890625\n",
      "Iteration: 160, BPR loss: 0.3206779296875\n",
      "Iteration: 170, BPR loss: 0.320774609375\n",
      "Iteration: 180, BPR loss: 0.32906025390625\n",
      "Iteration: 190, BPR loss: 0.3221517578125\n",
      "Iteration: 200, BPR loss: 0.3125048828125\n",
      "Iteration: 210, BPR loss: 0.315068359375\n",
      "Iteration: 220, BPR loss: 0.3197881591796875\n",
      "Iteration: 230, BPR loss: 0.327009521484375\n",
      "Iteration: 240, BPR loss: 0.30962060546875\n",
      "Iteration: 250, BPR loss: 0.30475322265625\n",
      "Iteration: 260, BPR loss: 0.306321044921875\n",
      "Iteration: 270, BPR loss: 0.30274921875\n",
      "Iteration: 280, BPR loss: 0.3165073974609375\n",
      "Iteration: 290, BPR loss: 0.30034169921875\n",
      "Iteration: 300, BPR loss: 0.302380029296875\n",
      "Iteration: 310, BPR loss: 0.3004657470703125\n",
      "Iteration: 320, BPR loss: 0.299585400390625\n",
      "Iteration: 330, BPR loss: 0.287264404296875\n",
      "Iteration: 340, BPR loss: 0.27721826171875\n",
      "Iteration: 350, BPR loss: 0.2708156005859375\n",
      "Iteration: 360, BPR loss: 0.2759964111328125\n",
      "Iteration: 370, BPR loss: 0.255393310546875\n",
      "Iteration: 380, BPR loss: 0.2553357177734375\n",
      "Iteration: 390, BPR loss: 0.25171064453125\n",
      "Iteration: 400, BPR loss: 0.240947509765625\n",
      "Iteration: 410, BPR loss: 0.23022548828125\n",
      "Iteration: 420, BPR loss: 0.229432275390625\n",
      "Iteration: 430, BPR loss: 0.228225390625\n",
      "Iteration: 440, BPR loss: 0.224038427734375\n",
      "Iteration: 450, BPR loss: 0.222687939453125\n",
      "Iteration: 460, BPR loss: 0.230066455078125\n",
      "Iteration: 470, BPR loss: 0.2160309326171875\n",
      "Iteration: 480, BPR loss: 0.2031192626953125\n",
      "Iteration: 490, BPR loss: 0.212870703125\n",
      "Iteration: 500, BPR loss: 0.2020672119140625\n",
      "Iteration: 510, BPR loss: 0.201957177734375\n",
      "Iteration: 520, BPR loss: 0.187684716796875\n",
      "Iteration: 530, BPR loss: 0.1967572509765625\n",
      "Iteration: 540, BPR loss: 0.191985302734375\n",
      "Iteration: 550, BPR loss: 0.186158740234375\n",
      "Iteration: 560, BPR loss: 0.191520654296875\n",
      "Iteration: 570, BPR loss: 0.1777461669921875\n",
      "Iteration: 580, BPR loss: 0.19019810791015626\n",
      "Iteration: 590, BPR loss: 0.1795095947265625\n",
      "Iteration: 600, BPR loss: 0.1802100830078125\n",
      "Iteration: 610, BPR loss: 0.1816257080078125\n",
      "Iteration: 620, BPR loss: 0.1719404541015625\n",
      "Iteration: 630, BPR loss: 0.1651873779296875\n",
      "Iteration: 640, BPR loss: 0.16731678466796876\n",
      "Iteration: 650, BPR loss: 0.1647728759765625\n",
      "Iteration: 660, BPR loss: 0.15684140625\n",
      "Iteration: 670, BPR loss: 0.1627210205078125\n",
      "Iteration: 680, BPR loss: 0.16192911376953126\n",
      "Iteration: 690, BPR loss: 0.1621592041015625\n",
      "Iteration: 700, BPR loss: 0.15939364013671875\n",
      "Iteration: 710, BPR loss: 0.15532265625\n",
      "Iteration: 720, BPR loss: 0.1510765380859375\n",
      "Iteration: 730, BPR loss: 0.1504855712890625\n",
      "Iteration: 740, BPR loss: 0.150566943359375\n",
      "Iteration: 750, BPR loss: 0.1448536865234375\n",
      "Iteration: 760, BPR loss: 0.1460753662109375\n",
      "Iteration: 770, BPR loss: 0.14802314453125\n",
      "Iteration: 780, BPR loss: 0.143336083984375\n",
      "Iteration: 790, BPR loss: 0.1509476318359375\n",
      "Iteration: 800, BPR loss: 0.14080888671875\n",
      "Iteration: 810, BPR loss: 0.14085306396484376\n",
      "Iteration: 820, BPR loss: 0.1397778564453125\n",
      "Iteration: 830, BPR loss: 0.14145947265625\n",
      "Iteration: 840, BPR loss: 0.13749136962890626\n",
      "Iteration: 850, BPR loss: 0.1275185302734375\n",
      "Iteration: 860, BPR loss: 0.13683023681640624\n",
      "Iteration: 870, BPR loss: 0.13650755615234375\n",
      "Iteration: 880, BPR loss: 0.1418909912109375\n",
      "Iteration: 890, BPR loss: 0.13393148193359375\n",
      "Iteration: 900, BPR loss: 0.13696278076171875\n",
      "Iteration: 910, BPR loss: 0.12831646728515625\n",
      "Iteration: 920, BPR loss: 0.130406787109375\n",
      "Iteration: 930, BPR loss: 0.1329706298828125\n",
      "Iteration: 940, BPR loss: 0.13370289306640626\n",
      "Iteration: 950, BPR loss: 0.12999783935546874\n",
      "Iteration: 960, BPR loss: 0.131112646484375\n",
      "Iteration: 970, BPR loss: 0.13506358642578126\n",
      "Iteration: 980, BPR loss: 0.1354625\n",
      "Iteration: 990, BPR loss: 0.12444688720703125\n",
      "Iteration: 1000, BPR loss: 0.1273071044921875\n",
      "CPU times: total: 2min 15s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model3.fit_ori(train3, k = 50, max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90fedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.1533774834437086\n",
      "Recall@10: 0.09292621273522449\n",
      "NDCG@10: 0.8107577104016125\n",
      "CPU times: total: 22.5 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "rec, pre, ndcg = model3.performance(test3, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920468ea",
   "metadata": {},
   "source": [
    "### 1M BPR + Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6491df15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.692225456237793\n",
      "Iteration: 20, BPR loss: 0.6890168190002441\n",
      "Iteration: 30, BPR loss: 0.6762951016426086\n",
      "Iteration: 40, BPR loss: 0.6451901197433472\n",
      "Iteration: 50, BPR loss: 0.5992444157600403\n",
      "Iteration: 60, BPR loss: 0.5506901144981384\n",
      "Iteration: 70, BPR loss: 0.5112587809562683\n",
      "Iteration: 80, BPR loss: 0.48153260350227356\n",
      "Iteration: 90, BPR loss: 0.45799756050109863\n",
      "Iteration: 100, BPR loss: 0.4361346662044525\n",
      "Iteration: 110, BPR loss: 0.42387861013412476\n",
      "Iteration: 120, BPR loss: 0.415990948677063\n",
      "Iteration: 130, BPR loss: 0.39986103773117065\n",
      "Iteration: 140, BPR loss: 0.3897932171821594\n",
      "Iteration: 150, BPR loss: 0.3817444145679474\n",
      "Iteration: 160, BPR loss: 0.37106946110725403\n",
      "Iteration: 170, BPR loss: 0.3724575936794281\n",
      "Iteration: 180, BPR loss: 0.364568829536438\n",
      "Iteration: 190, BPR loss: 0.3669742941856384\n",
      "Iteration: 200, BPR loss: 0.3616512417793274\n",
      "Iteration: 210, BPR loss: 0.35086536407470703\n",
      "Iteration: 220, BPR loss: 0.34876593947410583\n",
      "Iteration: 230, BPR loss: 0.3436574935913086\n",
      "Iteration: 240, BPR loss: 0.35448071360588074\n",
      "Iteration: 250, BPR loss: 0.3520190417766571\n",
      "Iteration: 260, BPR loss: 0.35056108236312866\n",
      "Iteration: 270, BPR loss: 0.33640268445014954\n",
      "Iteration: 280, BPR loss: 0.33996468782424927\n",
      "Iteration: 290, BPR loss: 0.3370296061038971\n",
      "Iteration: 300, BPR loss: 0.3380218744277954\n",
      "Iteration: 310, BPR loss: 0.3315573036670685\n",
      "Iteration: 320, BPR loss: 0.333693265914917\n",
      "Iteration: 330, BPR loss: 0.3396972715854645\n",
      "Iteration: 340, BPR loss: 0.32970866560935974\n",
      "Iteration: 350, BPR loss: 0.3340751528739929\n",
      "Iteration: 360, BPR loss: 0.32672634720802307\n",
      "Iteration: 370, BPR loss: 0.33036360144615173\n",
      "Iteration: 380, BPR loss: 0.3184005916118622\n",
      "Iteration: 390, BPR loss: 0.3234768509864807\n",
      "Iteration: 400, BPR loss: 0.32056909799575806\n",
      "Iteration: 410, BPR loss: 0.3198224902153015\n",
      "Iteration: 420, BPR loss: 0.3225966989994049\n",
      "Iteration: 430, BPR loss: 0.30917292833328247\n",
      "Iteration: 440, BPR loss: 0.3100430369377136\n",
      "Iteration: 450, BPR loss: 0.3176831603050232\n",
      "Iteration: 460, BPR loss: 0.3192176818847656\n",
      "Iteration: 470, BPR loss: 0.30322834849357605\n",
      "Iteration: 480, BPR loss: 0.31483522057533264\n",
      "Iteration: 490, BPR loss: 0.296324223279953\n",
      "Iteration: 500, BPR loss: 0.299489825963974\n",
      "Iteration: 510, BPR loss: 0.2892475426197052\n",
      "Iteration: 520, BPR loss: 0.29137611389160156\n",
      "Iteration: 530, BPR loss: 0.2913273870944977\n",
      "Iteration: 540, BPR loss: 0.28219500184059143\n",
      "Iteration: 550, BPR loss: 0.2848336398601532\n",
      "Iteration: 560, BPR loss: 0.27906283736228943\n",
      "Iteration: 570, BPR loss: 0.2743840217590332\n",
      "Iteration: 580, BPR loss: 0.2786329388618469\n",
      "Iteration: 590, BPR loss: 0.26675352454185486\n",
      "Iteration: 600, BPR loss: 0.27208930253982544\n",
      "Iteration: 610, BPR loss: 0.2685990035533905\n",
      "Iteration: 620, BPR loss: 0.2675586938858032\n",
      "Iteration: 630, BPR loss: 0.25491347908973694\n",
      "Iteration: 640, BPR loss: 0.24924330413341522\n",
      "Iteration: 650, BPR loss: 0.2553474009037018\n",
      "Iteration: 660, BPR loss: 0.24632452428340912\n",
      "Iteration: 670, BPR loss: 0.24679584801197052\n",
      "Iteration: 680, BPR loss: 0.2469479888677597\n",
      "Iteration: 690, BPR loss: 0.2419896423816681\n",
      "Iteration: 700, BPR loss: 0.23879848420619965\n",
      "Iteration: 710, BPR loss: 0.2353370040655136\n",
      "Iteration: 720, BPR loss: 0.23698636889457703\n",
      "Iteration: 730, BPR loss: 0.22720399498939514\n",
      "Iteration: 740, BPR loss: 0.23643758893013\n",
      "Iteration: 750, BPR loss: 0.22998422384262085\n",
      "Iteration: 760, BPR loss: 0.21962931752204895\n",
      "Iteration: 770, BPR loss: 0.22140316665172577\n",
      "Iteration: 780, BPR loss: 0.22972814738750458\n",
      "Iteration: 790, BPR loss: 0.2195798009634018\n",
      "Iteration: 800, BPR loss: 0.21697674691677094\n",
      "Iteration: 810, BPR loss: 0.2202720195055008\n",
      "Iteration: 820, BPR loss: 0.21290917694568634\n",
      "Iteration: 830, BPR loss: 0.21097919344902039\n",
      "Iteration: 840, BPR loss: 0.2042090892791748\n",
      "Iteration: 850, BPR loss: 0.2086036503314972\n",
      "Iteration: 860, BPR loss: 0.21567988395690918\n",
      "Iteration: 870, BPR loss: 0.20116020739078522\n",
      "Iteration: 880, BPR loss: 0.2019570916891098\n",
      "Iteration: 890, BPR loss: 0.19553956389427185\n",
      "Iteration: 900, BPR loss: 0.2061433494091034\n",
      "Iteration: 910, BPR loss: 0.19390228390693665\n",
      "Iteration: 920, BPR loss: 0.19707739353179932\n",
      "Iteration: 930, BPR loss: 0.1955610066652298\n",
      "Iteration: 940, BPR loss: 0.19586193561553955\n",
      "Iteration: 950, BPR loss: 0.19255903363227844\n",
      "Iteration: 960, BPR loss: 0.19017641246318817\n",
      "Iteration: 970, BPR loss: 0.18990465998649597\n",
      "Iteration: 980, BPR loss: 0.18794898688793182\n",
      "Iteration: 990, BPR loss: 0.1930970847606659\n",
      "Iteration: 1000, BPR loss: 0.18840236961841583\n",
      "CPU times: total: 35min 32s\n",
      "Wall time: 49min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model4.fit_dds(train3, dev3, k = 50, max_iter = 1000, batch=10000, dev_batch=10000, stepsize=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbb4e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.12781456953642384\n",
      "Recall@10: 0.07743851061268707\n",
      "NDCG@10: 0.821657343362663\n",
      "CPU times: total: 16.1 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "rec, pre, ndcg = model4.performance(test3, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
