{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce33bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c666ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPR, self).__init__()\n",
    "        \n",
    "        self.W = None             # user matrix\n",
    "        self.H = None             # item matrix\n",
    "        \n",
    "        self.Wsc = None        # scorer\n",
    "        self.Hsc = None \n",
    "        \n",
    "        self.user_items = {}\n",
    "        self.dev_user_items = {}\n",
    "        \n",
    "        self.uid = None\n",
    "        self.iid = None\n",
    "        \n",
    "        self.uid_dict = None      # serialize uid and iid\n",
    "        self.iid_dict = None      #  {(original id in dataset): (serial_idx)}\n",
    "        self.uid_dict_rev = None  # reverse key and value\n",
    "        self.iid_dict_rev = None  #  {(serial_idx): (original id in dataset)}\n",
    "        \n",
    "        self.rating_exp = None   # softmax sum\n",
    "        self.rating_exp_mul_H = None\n",
    "        \n",
    "    def _split(self, df, ratio):\n",
    "        train = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        test = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        for i in self.uid:\n",
    "            train_1, test_1 = train_test_split(df[df.iloc[:, 0] == i], train_size = ratio, shuffle = True, random_state = 5)\n",
    "            train = pd.concat([train, train_1])\n",
    "            test = pd.concat([test, test_1])\n",
    "        return train, test\n",
    "    \n",
    "    def split(self, df, train_size=0.8, test_size=0.1):\n",
    "        self.uid = np.asarray(list(set(df.iloc[:,0].values)))\n",
    "        self.iid = np.asarray(list(set(df.iloc[:,1].values)))\n",
    "        self.uid.sort()\n",
    "        self.iid.sort()\n",
    "        self.uid_dict = dict(zip(self.uid, [i for i in range(len(self.uid))]))\n",
    "        self.iid_dict = dict(zip(self.iid, [i for i in range(len(self.iid))]))\n",
    "        self.uid_dict_rev = {v: k for k, v in self.uid_dict.items()}\n",
    "        self.iid_dict_rev = {v: k for k, v in self.iid_dict.items()}\n",
    "        \n",
    "        train, test = self._split(df, train_size)\n",
    "        test, dev = self._split(test, test_size / (1 - train_size))\n",
    "        return train, test, dev\n",
    "    \n",
    "    def generate_train_batch(self, batch, sets):\n",
    "        train = []\n",
    "        for b in range(batch):\n",
    "            u = self.uid[np.random.randint(0, len(self.uid))]\n",
    "            i = sets[u][np.random.randint(0, len(sets[u]))]\n",
    "            j = self.iid[np.random.randint(0, len(self.iid))]\n",
    "            while j in sets[u]:\n",
    "                j = self.iid[np.random.randint(0, len(self.iid))]\n",
    "            train.append([self.uid_dict[u], self.iid_dict[i], self.iid_dict[j]])\n",
    "        return np.asarray(train) \n",
    "    \n",
    "#     def forward2(self, uids, iids, device):\n",
    "#         prob = []\n",
    "        \n",
    "#         self.rating_exp = torch.zeros(len(self.uid)).to(device)\n",
    "#         self.rating_exp_mul_H = torch.zeros([len(self.uid), self.H.shape[1]]).to(device)\n",
    "        \n",
    "#         for x in range(uids.size):\n",
    "#             uid = uids[x]\n",
    "#             iid = iids[x]\n",
    "            \n",
    "#             if self.rating_exp[uid] == 0:\n",
    "#                 ori_idxs = self.user_items[self.uid_dict_rev[uid] ]\n",
    "#                 emb_idxs = [self.iid_dict[ori_idx] for ori_idx in ori_idxs]\n",
    "#                 user_emb = self.Wsc[uid]\n",
    "#                 item_emb = self.Hsc[emb_idxs]\n",
    "                \n",
    "#                 user_item_exp_sc = torch.exp(torch.mv(item_emb, user_emb))\n",
    "               \n",
    "#                 self.rating_exp[uid] = torch.sum(user_item_exp_sc)\n",
    "#                 self.rating_exp_mul_H[uid] = torch.sum(user_item_exp_sc.unsqueeze(1).repeat(1, self.H.shape[1]) * item_emb, dim = 0)        \n",
    "                \n",
    "#             prob.append(torch.exp(torch.dot(self.Wsc[uid], self.Hsc[iid])) / self.rating_exp[uid]) \n",
    "#         print(self.rating_exp_mul_H[uids])\n",
    "#         return torch.tensor(prob).to(device)\n",
    "\n",
    "    def forward(self, uids, iids, device):\n",
    "        self.rating_exp = torch.zeros(len(self.uid)).to(device)\n",
    "        self.rating_exp_mul_H = torch.zeros([len(self.uid), self.H.shape[1]]).to(device)\n",
    "        \n",
    "        # 处理 idx 得到 embedded Wu Hi\n",
    "        ori_uids = [self.uid_dict_rev[uid] for uid in uids]\n",
    "        emb_idxs = [[ self.iid_dict[ori_idx] for ori_idx in self.user_items[ori_uid] ] for ori_uid in ori_uids]\n",
    "        item_emb = nn.utils.rnn.pad_sequence([self.Hsc[emb_idx] for emb_idx in emb_idxs], batch_first=True)\n",
    "        user_emb = self.Wsc[uids][:, None, :]\n",
    "        \n",
    "        # 计算批次内 user_item 得分\n",
    "        user_item_exp_sc = torch.sum(item_emb * user_emb, dim = -1)\n",
    "        mask = (user_item_exp_sc != 0).type(torch.float32)\n",
    "        # 取指数， mask 保证补 0 位还是 0\n",
    "        user_item_exp_sc = torch.exp(user_item_exp_sc) * mask\n",
    "        \n",
    "        # 计算指数和\n",
    "        self.rating_exp_mul_H[uids] = torch.sum(user_item_exp_sc.unsqueeze(2).repeat(1, 1, self.H.shape[1]) * item_emb, dim = 1)\n",
    "        self.rating_exp[uids] = torch.sum(user_item_exp_sc, dim = 1)\n",
    "        #返回 softmax probablilty of item i among user_items\n",
    "        return torch.exp(torch.sum(self.Wsc[uids] * self.Hsc[iids], dim = 1)) / self.rating_exp[uids]\n",
    "            \n",
    "    def fit_dds(self, df, dev, k, stepsize=0.05, max_iter=10, batch=10000):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        # 初始化 W，H\n",
    "        self.W = nn.Parameter(torch.rand(len(self.uid), k).to(device) * 0.01)   \n",
    "        self.H = nn.Parameter(torch.rand(len(self.iid), k).to(device) * 0.01) \n",
    "        \n",
    "        # 初始化 scorer\n",
    "        self.Wsc = torch.rand(len(self.uid), k).to(device) * 0.01    \n",
    "        self.Hsc = torch.rand(len(self.iid), k).to(device) * 0.01  \n",
    "        \n",
    "        # 创建字典：用户u对应他访问过的所有items集合    \n",
    "        self.user_items = df.groupby(df.columns[0])[df.columns[1]].apply(lambda x: np.array(x)).to_dict()\n",
    "        self.dev_user_items = dev.groupby(dev.columns[0])[dev.columns[1]].apply(lambda x: np.array(x)).to_dict()\n",
    "        \n",
    "        # 主模型优化器        \n",
    "        optimizer = optim.Adam([self.W, self.H], lr = stepsize)\n",
    "        \n",
    "        for x in range(max_iter):            \n",
    "            #取训练批次：uij三元组\n",
    "            uij = self.generate_train_batch(batch, self.user_items)\n",
    "            u = uij[:, 0]\n",
    "            i = uij[:, 1]\n",
    "            j = uij[:, 2]\n",
    "            u_emb = self.W[u]\n",
    "            i_emb = self.H[i]\n",
    "            j_emb = self.H[j]\n",
    "            \n",
    "            # 评分器概率分布，forward 返回 softmax 概率分布\n",
    "            score_prob = self.forward(u, i, device)     \n",
    "            \n",
    "            # 主模型参数更新\n",
    "            optimizer.zero_grad() \n",
    "            score_loss = -torch.mean(score_prob * torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb-j_emb),dim = 1))))\n",
    "            bpr_loss = -torch.mean(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
    "            score_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 训练集上 W,H 的梯度\n",
    "            W_grad_sum = self.W.grad.clone()\n",
    "            H_grad_sum = self.H.grad.clone()\n",
    "            \n",
    "            # 对数概率分布下 Wsc, Hsc 梯度\n",
    "            log_prob_Wsc_grad = torch.zeros((len(self.uid), k)).to(device)\n",
    "            log_prob_Hsc_grad = torch.zeros((len(self.iid), k)).to(device)\n",
    "            log_prob_Wsc_grad[u] = self.Hsc[i] - self.rating_exp_mul_H[u] / self.rating_exp[u].unsqueeze(1).repeat(1, k)\n",
    "            log_prob_Hsc_grad[i] = self.Wsc[u] * ((1 - score_prob).unsqueeze(1).repeat(1, k))\n",
    "            \n",
    "            #取 dev uij三元组\n",
    "            uij = self.generate_train_batch(5000, self.dev_user_items)\n",
    "            u = uij[:, 0]\n",
    "            i = uij[:, 1]\n",
    "            j = uij[:, 2]\n",
    "            u_emb = self.W[u]\n",
    "            i_emb = self.H[i]\n",
    "            j_emb = self.H[j]\n",
    "            \n",
    "            # 计算 dev 集上 W,H 的梯度\n",
    "            optimizer.zero_grad()\n",
    "            dev_loss = -torch.mean(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
    "            dev_loss.backward()\n",
    "            W_grad_dev_sum = self.W.grad.clone()    \n",
    "            H_grad_dev_sum = self.H.grad.clone()\n",
    "\n",
    "            # 计算 reward: reward 为 W,H 在训练集和 dev 集上的梯度积    \n",
    "            r_W = torch.sum(W_grad_sum * W_grad_dev_sum, dim=1)\n",
    "            r_H = torch.sum(H_grad_sum * H_grad_dev_sum, dim=1)\n",
    "            r_W = r_W.unsqueeze(1).repeat(1, k)\n",
    "            r_H = r_H.unsqueeze(1).repeat(1, k)\n",
    "\n",
    "            # Wsc，Hsc 更新\n",
    "            self.Wsc += r_W * log_prob_Wsc_grad\n",
    "            self.Hsc += r_H * log_prob_Hsc_grad\n",
    "\n",
    "            if ( x + 1 ) % 10 == 0:\n",
    "                print(f\"Iteration: {x+1}, BPR loss: {bpr_loss.item()}\")\n",
    "    \n",
    "    def fit_ori(self, df, k, stepsize=0.05, max_iter=10, batch=10000):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        self.W = nn.Parameter(torch.rand(len(self.uid), k).to(device) * 0.01)    # 初始化 W，H\n",
    "        self.H = nn.Parameter(torch.rand(len(self.iid), k).to(device) * 0.01)  \n",
    "        \n",
    "        # 创建字典：用户u对应他访问过的所有items集合\n",
    "        self.user_items = df.groupby(df.columns[0])[df.columns[1]].apply(lambda x: np.array(x)).to_dict()\n",
    "        \n",
    "        optimizer = optim.Adam([self.W, self.H], lr = stepsize)     # 主模型优化器\n",
    "        for x in range(max_iter):\n",
    "            #取训练批次：uij三元组\n",
    "            uij = self.generate_train_batch(batch, self.user_items)\n",
    "            \n",
    "            u = uij[:, 0]\n",
    "            i = uij[:, 1]\n",
    "            j = uij[:, 2]\n",
    "            u_emb = self.W[u]\n",
    "            i_emb = self.H[i]\n",
    "            j_emb = self.H[j]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = -torch.mean(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if ( x + 1 ) % 10 == 0:\n",
    "                print(f\"Iteration: {x+1}, BPR loss: {loss.item()}\")\n",
    "    \n",
    "    def _predict(self, uid, items, n):\n",
    "        item = [self.iid_dict[i] for i in items]\n",
    "        user = self.uid_dict[uid]\n",
    "        scores = torch.mv(self.H[item], self.W[user])\n",
    "        top_N = list(zip(items, scores.detach().cpu().numpy()))\n",
    "        return sorted(top_N, key=lambda s: s[1], reverse=True)[:n]\n",
    "\n",
    "    def NDCG(self, uid, test, n):         # 用模型排序+真实分数计算 DCG, 重排后计算 iDCG\n",
    "        test_user = test[test.iloc[:, 0] == uid]\n",
    "        rating = self._predict(uid, test_user.iloc[:, 1].values, n)\n",
    "        irating =sorted(test_user.iloc[:, 2].values, reverse=True)\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        if n > len(irating): n = len(irating)  \n",
    "        for i in range(n):\n",
    "            r = test_user[test_user.iloc[:, 1]==rating[i][0]].iloc[0, 2]\n",
    "            dcg += 1.0 * (2**r - 1) / math.log(i + 2, 2)\n",
    "            idcg += 1.0 * (2**irating[i] - 1) / math.log(i + 2, 2)\n",
    "        return dcg / idcg\n",
    "\n",
    "    def performance(self, test, n):      # Output recall@n, precision@n, NDCG@n\n",
    "        hit = 0\n",
    "        n_recall = 0\n",
    "        n_precision = 0\n",
    "        ndcg = 0\n",
    "        for i in self.uid:\n",
    "            # Items that User i hasn't tried in training set\n",
    "            unknown_items = np.setdiff1d(self.iid, self.user_items[i])\n",
    "            # Items that User i actually tried in testing set\n",
    "            known_items = test[test.iloc[:, 0] == i].iloc[:, 1].values\n",
    "            \n",
    "            #目标：预测 unknown items 中的top_N，若击中test中的items，则为有效预测\n",
    "            ru = self._predict(i, unknown_items, n)\n",
    "            for item, pui in ru:\n",
    "                if item in known_items:\n",
    "                    hit += 1\n",
    "            n_recall += len(known_items)\n",
    "            n_precision += n\n",
    "            ndcg += self.NDCG(i, test, n)\n",
    "\n",
    "        recall = hit / (1.0 * n_recall)\n",
    "        precision = hit / (1.0 * n_precision)\n",
    "        ndcg /= len(self.uid)\n",
    "        return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "319ffcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./ml-100k/u.data\", sep=\"\\t\", names=['user id', 'item id', 'rating', 'timestamp'])\n",
    "df2 = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", names=['user id', 'item id', 'rating', 'timestamp'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2cdfb1",
   "metadata": {},
   "source": [
    "### 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da1781ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79619, 4)\n",
      "(9942, 4)\n",
      "(10439, 4)\n"
     ]
    }
   ],
   "source": [
    "model1 = BPR()\n",
    "model2 = BPR()\n",
    "train1, test1, dev1 = model1.split(df1)\n",
    "train2, test2, dev2 = model2.split(df1)\n",
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(dev1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a055d2a",
   "metadata": {},
   "source": [
    "### 100K Pure BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9403a3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.34321820735931396\n",
      "Iteration: 20, BPR loss: 0.2845911681652069\n",
      "Iteration: 30, BPR loss: 0.1951943188905716\n",
      "Iteration: 40, BPR loss: 0.1442578136920929\n",
      "Iteration: 50, BPR loss: 0.12120641767978668\n",
      "Iteration: 60, BPR loss: 0.10743703693151474\n",
      "Iteration: 70, BPR loss: 0.10088685899972916\n",
      "Iteration: 80, BPR loss: 0.09578598290681839\n",
      "Iteration: 90, BPR loss: 0.09169719368219376\n",
      "Iteration: 100, BPR loss: 0.08609083294868469\n",
      "Iteration: 110, BPR loss: 0.078936368227005\n",
      "Iteration: 120, BPR loss: 0.0768565833568573\n",
      "Iteration: 130, BPR loss: 0.07956204563379288\n",
      "Iteration: 140, BPR loss: 0.07245401293039322\n",
      "Iteration: 150, BPR loss: 0.08067290484905243\n",
      "Iteration: 160, BPR loss: 0.08181027323007584\n",
      "Iteration: 170, BPR loss: 0.07737747579813004\n",
      "Iteration: 180, BPR loss: 0.07716871052980423\n",
      "Iteration: 190, BPR loss: 0.07087761908769608\n",
      "Iteration: 200, BPR loss: 0.0784105733036995\n",
      "Iteration: 210, BPR loss: 0.07919120043516159\n",
      "Iteration: 220, BPR loss: 0.07167080044746399\n",
      "Iteration: 230, BPR loss: 0.07503772526979446\n",
      "Iteration: 240, BPR loss: 0.07903249561786652\n",
      "Iteration: 250, BPR loss: 0.07255452126264572\n",
      "Iteration: 260, BPR loss: 0.06874574720859528\n",
      "Iteration: 270, BPR loss: 0.08235594630241394\n",
      "Iteration: 280, BPR loss: 0.07750663161277771\n",
      "Iteration: 290, BPR loss: 0.06856115907430649\n",
      "Iteration: 300, BPR loss: 0.0722869262099266\n",
      "Iteration: 310, BPR loss: 0.0820123627781868\n",
      "Iteration: 320, BPR loss: 0.08247686922550201\n",
      "Iteration: 330, BPR loss: 0.07609003037214279\n",
      "Iteration: 340, BPR loss: 0.08451205492019653\n",
      "Iteration: 350, BPR loss: 0.08320482820272446\n",
      "Iteration: 360, BPR loss: 0.06699372082948685\n",
      "Iteration: 370, BPR loss: 0.06559192389249802\n",
      "Iteration: 380, BPR loss: 0.0728871077299118\n",
      "Iteration: 390, BPR loss: 0.06915579736232758\n",
      "Iteration: 400, BPR loss: 0.07646550983190536\n",
      "Iteration: 410, BPR loss: 0.08105254173278809\n",
      "Iteration: 420, BPR loss: 0.08157609403133392\n",
      "Iteration: 430, BPR loss: 0.0691855400800705\n",
      "Iteration: 440, BPR loss: 0.0714772567152977\n",
      "Iteration: 450, BPR loss: 0.08439984917640686\n",
      "Iteration: 460, BPR loss: 0.07405485957860947\n",
      "Iteration: 470, BPR loss: 0.06887137144804001\n",
      "Iteration: 480, BPR loss: 0.07746098190546036\n",
      "Iteration: 490, BPR loss: 0.07026071846485138\n",
      "Iteration: 500, BPR loss: 0.06790471076965332\n",
      "CPU times: total: 1min 2s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit_ori(train1, k = 50, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb56a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.10498409331919406\n",
      "Recall@10: 0.0995775497887749\n",
      "NDCG@10: 0.8212617984439188\n",
      "CPU times: total: 1min 24s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "rec, pre, ndcg = model1.performance(test1, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f9423",
   "metadata": {},
   "source": [
    "### 100K BPR + Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd574457",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.36946091055870056\n",
      "Iteration: 20, BPR loss: 0.3186231553554535\n",
      "Iteration: 30, BPR loss: 0.24832765758037567\n",
      "Iteration: 40, BPR loss: 0.16737757623195648\n",
      "Iteration: 50, BPR loss: 0.14268428087234497\n",
      "Iteration: 60, BPR loss: 0.12022192031145096\n",
      "Iteration: 70, BPR loss: 0.11052170395851135\n",
      "Iteration: 80, BPR loss: 0.11082051694393158\n",
      "Iteration: 90, BPR loss: 0.10729774832725525\n",
      "Iteration: 100, BPR loss: 0.09982667863368988\n",
      "Iteration: 110, BPR loss: 0.09177907556295395\n",
      "Iteration: 120, BPR loss: 0.08649598062038422\n",
      "Iteration: 130, BPR loss: 0.09156856685876846\n",
      "Iteration: 140, BPR loss: 0.08470410108566284\n",
      "Iteration: 150, BPR loss: 0.08146990835666656\n",
      "Iteration: 160, BPR loss: 0.08098555356264114\n",
      "Iteration: 170, BPR loss: 0.08361070603132248\n",
      "Iteration: 180, BPR loss: 0.07724657654762268\n",
      "Iteration: 190, BPR loss: 0.08311904966831207\n",
      "Iteration: 200, BPR loss: 0.08271296322345734\n",
      "Iteration: 210, BPR loss: 0.08003785461187363\n",
      "Iteration: 220, BPR loss: 0.07815136015415192\n",
      "Iteration: 230, BPR loss: 0.07668274641036987\n",
      "Iteration: 240, BPR loss: 0.0759492814540863\n",
      "Iteration: 250, BPR loss: 0.08250664919614792\n",
      "Iteration: 260, BPR loss: 0.09138160198926926\n",
      "Iteration: 270, BPR loss: 0.0762779712677002\n",
      "Iteration: 280, BPR loss: 0.08532681316137314\n",
      "Iteration: 290, BPR loss: 0.07638940215110779\n",
      "Iteration: 300, BPR loss: 0.08673663437366486\n",
      "Iteration: 310, BPR loss: 0.07927288860082626\n",
      "Iteration: 320, BPR loss: 0.08065209537744522\n",
      "Iteration: 330, BPR loss: 0.08310233056545258\n",
      "Iteration: 340, BPR loss: 0.09352312982082367\n",
      "Iteration: 350, BPR loss: 0.07749222964048386\n",
      "Iteration: 360, BPR loss: 0.07332859188318253\n",
      "Iteration: 370, BPR loss: 0.08854254335165024\n",
      "Iteration: 380, BPR loss: 0.08737336844205856\n",
      "Iteration: 390, BPR loss: 0.07719038426876068\n",
      "Iteration: 400, BPR loss: 0.08913567662239075\n",
      "Iteration: 410, BPR loss: 0.08979978412389755\n",
      "Iteration: 420, BPR loss: 0.08307290077209473\n",
      "Iteration: 430, BPR loss: 0.07464446872472763\n",
      "Iteration: 440, BPR loss: 0.09439204633235931\n",
      "Iteration: 450, BPR loss: 0.08580344170331955\n",
      "Iteration: 460, BPR loss: 0.09341953694820404\n",
      "Iteration: 470, BPR loss: 0.09474913775920868\n",
      "Iteration: 480, BPR loss: 0.09277409315109253\n",
      "Iteration: 490, BPR loss: 0.0988626778125763\n",
      "Iteration: 500, BPR loss: 0.08614350110292435\n",
      "CPU times: total: 6min 48s\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2.fit_dds(train1, dev1, k = 50, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b0edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.10869565217391304\n",
      "Recall@10: 0.10309796821565077\n",
      "NDCG@10: 0.8186659970475956\n",
      "CPU times: total: 1min\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10\n",
    "rec, pre, ndcg = model2.performance(test1, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c144c",
   "metadata": {},
   "source": [
    "### 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f23925bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797758, 4)\n",
      "(99692, 4)\n",
      "(102759, 4)\n"
     ]
    }
   ],
   "source": [
    "model3 = BPR()\n",
    "model4 = BPR()\n",
    "train3, test3, dev3 = model3.split(df2)\n",
    "train4, test4, dev4 = model4.split(df2)\n",
    "print(train3.shape)\n",
    "print(test3.shape)\n",
    "print(dev3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88834487",
   "metadata": {},
   "source": [
    "### 1M Pure BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c81b6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.37315675616264343\n",
      "Iteration: 20, BPR loss: 0.35101908445358276\n",
      "Iteration: 30, BPR loss: 0.3575577139854431\n",
      "Iteration: 40, BPR loss: 0.33635327219963074\n",
      "Iteration: 50, BPR loss: 0.32147300243377686\n",
      "Iteration: 60, BPR loss: 0.31918105483055115\n",
      "Iteration: 70, BPR loss: 0.2890665531158447\n",
      "Iteration: 80, BPR loss: 0.2785409688949585\n",
      "Iteration: 90, BPR loss: 0.26115262508392334\n",
      "Iteration: 100, BPR loss: 0.24021996557712555\n",
      "Iteration: 110, BPR loss: 0.23213715851306915\n",
      "Iteration: 120, BPR loss: 0.20239047706127167\n",
      "Iteration: 130, BPR loss: 0.21163949370384216\n",
      "Iteration: 140, BPR loss: 0.20129649341106415\n",
      "Iteration: 150, BPR loss: 0.21305468678474426\n",
      "Iteration: 160, BPR loss: 0.20476847887039185\n",
      "Iteration: 170, BPR loss: 0.19826120138168335\n",
      "Iteration: 180, BPR loss: 0.19827216863632202\n",
      "Iteration: 190, BPR loss: 0.18471236526966095\n",
      "Iteration: 200, BPR loss: 0.2061823606491089\n",
      "Iteration: 210, BPR loss: 0.19735468924045563\n",
      "Iteration: 220, BPR loss: 0.1969861090183258\n",
      "Iteration: 230, BPR loss: 0.1848352551460266\n",
      "Iteration: 240, BPR loss: 0.19100446999073029\n",
      "Iteration: 250, BPR loss: 0.18875150382518768\n",
      "Iteration: 260, BPR loss: 0.18751178681850433\n",
      "Iteration: 270, BPR loss: 0.18264992535114288\n",
      "Iteration: 280, BPR loss: 0.184179425239563\n",
      "Iteration: 290, BPR loss: 0.18405401706695557\n",
      "Iteration: 300, BPR loss: 0.18192721903324127\n",
      "Iteration: 310, BPR loss: 0.187930166721344\n",
      "Iteration: 320, BPR loss: 0.17560335993766785\n",
      "Iteration: 330, BPR loss: 0.17820504307746887\n",
      "Iteration: 340, BPR loss: 0.17546012997627258\n",
      "Iteration: 350, BPR loss: 0.16982358694076538\n",
      "Iteration: 360, BPR loss: 0.17813332378864288\n",
      "Iteration: 370, BPR loss: 0.18782508373260498\n",
      "Iteration: 380, BPR loss: 0.1790180802345276\n",
      "Iteration: 390, BPR loss: 0.18234799802303314\n",
      "Iteration: 400, BPR loss: 0.16748176515102386\n",
      "Iteration: 410, BPR loss: 0.1808767020702362\n",
      "Iteration: 420, BPR loss: 0.17586232721805573\n",
      "Iteration: 430, BPR loss: 0.18071100115776062\n",
      "Iteration: 440, BPR loss: 0.178573340177536\n",
      "Iteration: 450, BPR loss: 0.18304762244224548\n",
      "Iteration: 460, BPR loss: 0.176291823387146\n",
      "Iteration: 470, BPR loss: 0.16676129400730133\n",
      "Iteration: 480, BPR loss: 0.16794849932193756\n",
      "Iteration: 490, BPR loss: 0.17035211622714996\n",
      "Iteration: 500, BPR loss: 0.16130705177783966\n"
     ]
    }
   ],
   "source": [
    "model3.fit_ori(train3, k = 20, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c90fedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.10902317880794701\n",
      "Recall@10: 0.06605344460939694\n",
      "NDCG@10: 0.7998781089801381\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "rec, pre, ndcg = model3.performance(test3, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920468ea",
   "metadata": {},
   "source": [
    "### 1M BPR + Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "135c4284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, BPR loss: 0.4070197641849518\n",
      "Iteration: 20, BPR loss: 0.3906244933605194\n",
      "Iteration: 30, BPR loss: 0.3765500485897064\n",
      "Iteration: 40, BPR loss: 0.3531898856163025\n",
      "Iteration: 50, BPR loss: 0.3345780670642853\n",
      "Iteration: 60, BPR loss: 0.31240397691726685\n",
      "Iteration: 70, BPR loss: 0.3207390010356903\n",
      "Iteration: 80, BPR loss: 0.2927694320678711\n",
      "Iteration: 90, BPR loss: 0.2807278335094452\n",
      "Iteration: 100, BPR loss: 0.27128997445106506\n",
      "Iteration: 110, BPR loss: 0.2651827931404114\n",
      "Iteration: 120, BPR loss: 0.2417038530111313\n",
      "Iteration: 130, BPR loss: 0.22670380771160126\n",
      "Iteration: 140, BPR loss: 0.21507641673088074\n",
      "Iteration: 150, BPR loss: 0.22000204026699066\n",
      "Iteration: 160, BPR loss: 0.19937869906425476\n",
      "Iteration: 170, BPR loss: 0.21532931923866272\n",
      "Iteration: 180, BPR loss: 0.21381667256355286\n",
      "Iteration: 190, BPR loss: 0.20928165316581726\n",
      "Iteration: 200, BPR loss: 0.21017666161060333\n",
      "Iteration: 210, BPR loss: 0.21056024730205536\n",
      "Iteration: 220, BPR loss: 0.20587335526943207\n",
      "Iteration: 230, BPR loss: 0.20308305323123932\n",
      "Iteration: 240, BPR loss: 0.20419752597808838\n",
      "Iteration: 250, BPR loss: 0.19331684708595276\n",
      "Iteration: 260, BPR loss: 0.20332147181034088\n",
      "Iteration: 270, BPR loss: 0.2046978771686554\n",
      "Iteration: 280, BPR loss: 0.20793482661247253\n",
      "Iteration: 290, BPR loss: 0.19787035882472992\n",
      "Iteration: 300, BPR loss: 0.20928768813610077\n",
      "Iteration: 310, BPR loss: 0.20537148416042328\n",
      "Iteration: 320, BPR loss: 0.2046358287334442\n",
      "Iteration: 330, BPR loss: 0.19502511620521545\n",
      "Iteration: 340, BPR loss: 0.1973130851984024\n",
      "Iteration: 350, BPR loss: 0.19273540377616882\n",
      "Iteration: 360, BPR loss: 0.20677365362644196\n",
      "Iteration: 370, BPR loss: 0.21152463555335999\n",
      "Iteration: 380, BPR loss: 0.19338089227676392\n",
      "Iteration: 390, BPR loss: 0.1992470920085907\n",
      "Iteration: 400, BPR loss: 0.19936850666999817\n",
      "Iteration: 410, BPR loss: 0.19568033516407013\n",
      "Iteration: 420, BPR loss: 0.200762078166008\n",
      "Iteration: 430, BPR loss: 0.19423772394657135\n",
      "Iteration: 440, BPR loss: 0.1960047036409378\n",
      "Iteration: 450, BPR loss: 0.1973915994167328\n",
      "Iteration: 460, BPR loss: 0.20368976891040802\n",
      "Iteration: 470, BPR loss: 0.2045694887638092\n",
      "Iteration: 480, BPR loss: 0.2044144719839096\n",
      "Iteration: 490, BPR loss: 0.19156932830810547\n",
      "Iteration: 500, BPR loss: 0.21063746511936188\n"
     ]
    }
   ],
   "source": [
    "model4.fit_dds(train3, dev3, k = 20, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbbb4e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.1022682119205298\n",
      "Recall@10: 0.06196083938530674\n",
      "NDCG@10: 0.8012535429823792\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "rec, pre, ndcg = model4.performance(test3, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
