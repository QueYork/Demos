{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce33bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3755360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(object):\n",
    "    def __init__(self):\n",
    "        self.W = None             # user matrix\n",
    "        self.H = None             # item matrix\n",
    "        \n",
    "        self.uid = None            # uid,iid without duplicates\n",
    "        self.iid = None\n",
    "        \n",
    "        self.user_items = {}       # 用户u对应他访问过的所有items集合\n",
    "        \n",
    "        self.uid_dict = None      # serialize uid and iid\n",
    "        self.iid_dict = None      #  {(original id in dataset): (serial_idx)}\n",
    "        self.uid_dict_rev = None  # reverse key and value\n",
    "        self.iid_dict_rev = None  #  {(serial_idx): (original id in dataset)}\n",
    "        \n",
    "    def split(self, df, ratio=0.8):\n",
    "        self.uid = np.array(list(set(df.iloc[:,0].values)))\n",
    "        self.iid = np.array(list(set(df.iloc[:,1].values)))\n",
    "        self.uid.sort()\n",
    "        self.iid.sort()\n",
    "        \n",
    "        self.uid_dict = dict(zip(self.uid, [i for i in range(len(self.uid))]))\n",
    "        self.iid_dict = dict(zip(self.iid, [i for i in range(len(self.iid))]))\n",
    "        self.uid_dict_rev = {v : k for k, v in self.uid_dict.items()}\n",
    "        self.iid_dict_rev = {v : k for k, v in self.iid_dict.items()}\n",
    "        \n",
    "        train = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        test = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        for i in self.uid:\n",
    "            train_1, test_1 = train_test_split(df[df.iloc[:, 0] == i], train_size = ratio)\n",
    "            train = pd.concat([train, train_1])\n",
    "            test = pd.concat([test, test_1])\n",
    "        return train, test\n",
    "                            \n",
    "    def generate_train_batch(self, df, batch):\n",
    "        train = []\n",
    "        for b in range(batch):\n",
    "            u = np.random.choice(self.uid, size=1)[0]\n",
    "            i = np.random.choice(self.user_items[u], size=1)[0]\n",
    "            j = np.random.choice(self.iid, size=1)[0]\n",
    "            while j in self.user_items[u]:\n",
    "                j = np.random.choice(self.iid, size=1)[0]\n",
    "            \n",
    "            train.append([self.uid_dict[u], self.iid_dict[i], self.iid_dict[j]])\n",
    "        return train            \n",
    "            \n",
    "    def fit(self, df, k, stepsize=0.05, regulation_rate=0.0001, max_iter=50, batch=10000):\n",
    "        self.W = np.random.rand(len(self.uid), k)*0.01      # 初始化 W，H\n",
    "        self.H = np.random.rand(len(self.iid), k)*0.01\n",
    "        \n",
    "        for u in self.uid:                                # 创建字典：用户u对应他访问过的所有items集合\n",
    "            self.user_items[u] = df[df.iloc[:, 0]==u].iloc[:, 1].values\n",
    "                            \n",
    "        for x in range(max_iter):             # Use stochastic gradient descent method to solve W & H\n",
    "            loss = 0\n",
    "            for u, i, j in self.generate_train_batch(df, batch):\n",
    "                xuij = np.dot(self.W[u], self.H[i]) - np.dot(self.W[u], self.H[j])\n",
    "                sigmoid = 1.0 / (1 + math.exp(xuij))\n",
    "                loss += -np.log(1.0/(1 + math.exp(-xuij)))\n",
    "                self.W[u] += stepsize * (sigmoid * (self.H[i] - self.H[j]) + regulation_rate * self.W[u])\n",
    "                self.H[i] += stepsize * (sigmoid * self.W[u] + regulation_rate * self.H[i])\n",
    "                self.H[j] += stepsize * (-sigmoid * self.W[u] + regulation_rate * self.H[j])\n",
    "            print(f\"Iteration: {x+1}, BPR loss: {loss / batch}\")\n",
    "            \n",
    "    \n",
    "    def predict(self, user, n):      # Top-N recommendation\n",
    "        top_N = []\n",
    "        for i in self.iid:\n",
    "            if i not in self.user_items[user]:\n",
    "                top_N.append((i, np.dot(self.W[self.uid_dict[user]], self.H[self.iid_dict[i]]))) \n",
    "        return sorted(top_N, key=lambda s: s[1], reverse=True)[:n]\n",
    "    \n",
    "    def _predict(self, uid, items, n):\n",
    "        top_N = []\n",
    "        \n",
    "        for i in range(len(items)):\n",
    "            user = self.uid_dict[uid]\n",
    "            item = self.iid_dict[items[i]]\n",
    "            top_N.append((items[i], np.dot(self.W[user], self.H[item])))\n",
    "                \n",
    "        return sorted(top_N, key=lambda s: s[1], reverse=True)[:n]\n",
    "    \n",
    "    def NDCG(self, uid, test, n):         # 用模型排序+真实分数计算 DCG, 重排后计算 iDCG\n",
    "        test_user = test[test.iloc[:, 0] == uid]\n",
    "        rating = self._predict(uid, test_user.iloc[:, 1].values, n)\n",
    "        irating =sorted(test_user.iloc[:, 2].values, reverse=True)\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        if n > len(irating): n = len(irating)  \n",
    "        for i in range(n):\n",
    "            r = test_user[test_user.iloc[:, 1]==rating[i][0]].iloc[0, 2]\n",
    "            dcg += 1.0*(2**r - 1)/math.log(i + 2, 2)\n",
    "            idcg += 1.0*(2**irating[i] - 1)/math.log(i + 2, 2)\n",
    "        return dcg/idcg\n",
    "    \n",
    "    def performance(self, test, n):      # Output recall@n, precision@n, NDCG@n\n",
    "        hit = 0\n",
    "        n_recall = 0\n",
    "        n_precision = 0\n",
    "        ndcg = 0\n",
    "        for i in self.uid:\n",
    "            # Items that User i hasn't tried in training set\n",
    "            unknown_items = np.setdiff1d(self.iid, self.user_items[i])\n",
    "            # Items that User i actually tried in testing set\n",
    "            known_items = test[test.iloc[:, 0]==i].iloc[:, 1].values\n",
    "            \n",
    "            #目标：预测 unknown items 中的top_N，若击中test中的items，则为有效预测\n",
    "            ru = self._predict(i, unknown_items, n)\n",
    "            for item ,pui in ru:\n",
    "                if item in known_items:\n",
    "                    hit += 1\n",
    "            n_recall += len(known_items)\n",
    "            n_precision += n\n",
    "            ndcg += self.NDCG(i, test, n)  \n",
    "            \n",
    "        recall = hit / (1.0 * n_recall)\n",
    "        precision = hit / (1.0 * n_precision)\n",
    "        ndcg /= len(self.uid)\n",
    "        return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319ffcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./ml-100k/u.data\", sep=\"\\t\", names=['user id', 'item id', 'rating', 'timestamp'])\n",
    "df2 = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", names=['user id', 'item id', 'rating', 'timestamp'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1781ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79619, 4)\n",
      "(20381, 4)\n"
     ]
    }
   ],
   "source": [
    "model1 = BPR()\n",
    "train1, test1 = model1.split(df1)\n",
    "print(train1.shape)\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ae2636",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, BPR loss: 0.6929748395537708\n",
      "Iteration: 2, BPR loss: 0.692526100492518\n",
      "Iteration: 3, BPR loss: 0.6914981718364809\n",
      "Iteration: 4, BPR loss: 0.68940650195129\n",
      "Iteration: 5, BPR loss: 0.6846823433440529\n",
      "Iteration: 6, BPR loss: 0.6741591217006015\n",
      "Iteration: 7, BPR loss: 0.6540458305789799\n",
      "Iteration: 8, BPR loss: 0.6213969569748574\n",
      "Iteration: 9, BPR loss: 0.5811982071004226\n",
      "Iteration: 10, BPR loss: 0.5335392928255712\n",
      "Iteration: 11, BPR loss: 0.5011073925654803\n",
      "Iteration: 12, BPR loss: 0.4591854252438183\n",
      "Iteration: 13, BPR loss: 0.43496004394497895\n",
      "Iteration: 14, BPR loss: 0.4035510545630963\n",
      "Iteration: 15, BPR loss: 0.38380218849348047\n",
      "Iteration: 16, BPR loss: 0.3723646206354857\n",
      "Iteration: 17, BPR loss: 0.3579825209107358\n",
      "Iteration: 18, BPR loss: 0.34987747326314106\n",
      "Iteration: 19, BPR loss: 0.33959152620019506\n",
      "Iteration: 20, BPR loss: 0.33661941706268494\n",
      "Iteration: 21, BPR loss: 0.33677691400180854\n",
      "Iteration: 22, BPR loss: 0.3320410187215783\n",
      "Iteration: 23, BPR loss: 0.32655997723959956\n",
      "Iteration: 24, BPR loss: 0.32497919116823365\n",
      "Iteration: 25, BPR loss: 0.32273521735961114\n",
      "Iteration: 26, BPR loss: 0.31637591181970026\n",
      "Iteration: 27, BPR loss: 0.3169034769081894\n",
      "Iteration: 28, BPR loss: 0.31166889827610766\n",
      "Iteration: 29, BPR loss: 0.3116412915335378\n",
      "Iteration: 30, BPR loss: 0.31340309147837336\n",
      "Iteration: 31, BPR loss: 0.3214187842405804\n",
      "Iteration: 32, BPR loss: 0.30693735474964995\n",
      "Iteration: 33, BPR loss: 0.2959574364752152\n",
      "Iteration: 34, BPR loss: 0.297485635044687\n",
      "Iteration: 35, BPR loss: 0.30718791164243325\n",
      "Iteration: 36, BPR loss: 0.3001987667360098\n",
      "Iteration: 37, BPR loss: 0.30862714893129845\n",
      "Iteration: 38, BPR loss: 0.29763540472390776\n",
      "Iteration: 39, BPR loss: 0.2973617624015545\n",
      "Iteration: 40, BPR loss: 0.2943840374457272\n",
      "Iteration: 41, BPR loss: 0.3022751245352947\n",
      "Iteration: 42, BPR loss: 0.3011546631993436\n",
      "Iteration: 43, BPR loss: 0.2951847981368774\n",
      "Iteration: 44, BPR loss: 0.29469231899325293\n",
      "Iteration: 45, BPR loss: 0.3069251546077001\n",
      "Iteration: 46, BPR loss: 0.2867238797117166\n",
      "Iteration: 47, BPR loss: 0.30214192381944044\n",
      "Iteration: 48, BPR loss: 0.2866960394478881\n",
      "Iteration: 49, BPR loss: 0.28525818384828966\n",
      "Iteration: 50, BPR loss: 0.28733454663261265\n"
     ]
    }
   ],
   "source": [
    "model1.fit(train1, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a79464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.20477200424178155\n",
      "Recall@10: 0.09474510573573426\n",
      "NDCG@10: 0.7421273373589784\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "rec, pre, ndcg = model1.performance(test1, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cd7874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(121, 2.8629200289799845),\n",
       " (294, 2.813426070148068),\n",
       " (1, 2.808156494319421),\n",
       " (288, 2.6146443273667526),\n",
       " (300, 2.614524661016716)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b0dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797758, 4)\n",
      "(202451, 4)\n"
     ]
    }
   ],
   "source": [
    "model2 = BPR()\n",
    "train2, test2 = model2.split(df2)\n",
    "print(train2.shape)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81813b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, BPR loss: 0.6931145365035107\n",
      "Iteration: 2, BPR loss: 0.6930497704202407\n",
      "Iteration: 3, BPR loss: 0.692981379781051\n",
      "Iteration: 4, BPR loss: 0.6928952941246321\n",
      "Iteration: 5, BPR loss: 0.6928064990427695\n",
      "Iteration: 6, BPR loss: 0.6926989438247637\n",
      "Iteration: 7, BPR loss: 0.6925594302233244\n",
      "Iteration: 8, BPR loss: 0.6924054635574257\n",
      "Iteration: 9, BPR loss: 0.6921860716157336\n",
      "Iteration: 10, BPR loss: 0.6919499688104982\n",
      "Iteration: 11, BPR loss: 0.6916190839286426\n",
      "Iteration: 12, BPR loss: 0.691176670567771\n",
      "Iteration: 13, BPR loss: 0.6906964090650071\n",
      "Iteration: 14, BPR loss: 0.6900096049721145\n",
      "Iteration: 15, BPR loss: 0.6892876639206811\n",
      "Iteration: 16, BPR loss: 0.6881562471704531\n",
      "Iteration: 17, BPR loss: 0.687001635204638\n",
      "Iteration: 18, BPR loss: 0.6852000272540268\n",
      "Iteration: 19, BPR loss: 0.6835414906008254\n",
      "Iteration: 20, BPR loss: 0.6806959403908283\n",
      "Iteration: 21, BPR loss: 0.678390059291369\n",
      "Iteration: 22, BPR loss: 0.6748249178400716\n",
      "Iteration: 23, BPR loss: 0.6706740459608118\n",
      "Iteration: 24, BPR loss: 0.6650386716739741\n",
      "Iteration: 25, BPR loss: 0.6602911626162634\n",
      "Iteration: 26, BPR loss: 0.6530759768832433\n",
      "Iteration: 27, BPR loss: 0.6448675149679264\n",
      "Iteration: 28, BPR loss: 0.6362376364765938\n",
      "Iteration: 29, BPR loss: 0.6265321981379895\n",
      "Iteration: 30, BPR loss: 0.6188823408802144\n",
      "Iteration: 31, BPR loss: 0.6052951239057904\n",
      "Iteration: 32, BPR loss: 0.5936710816522792\n",
      "Iteration: 33, BPR loss: 0.5834643387728137\n",
      "Iteration: 34, BPR loss: 0.5684902408110009\n",
      "Iteration: 35, BPR loss: 0.5628342940165567\n",
      "Iteration: 36, BPR loss: 0.5475659763558538\n",
      "Iteration: 37, BPR loss: 0.5372076893082326\n",
      "Iteration: 38, BPR loss: 0.5295022947071325\n",
      "Iteration: 39, BPR loss: 0.5166871280504667\n",
      "Iteration: 40, BPR loss: 0.499431521868982\n",
      "Iteration: 41, BPR loss: 0.49318947760633863\n",
      "Iteration: 42, BPR loss: 0.48043826258128913\n",
      "Iteration: 43, BPR loss: 0.4719245140769334\n",
      "Iteration: 44, BPR loss: 0.45952122821041186\n",
      "Iteration: 45, BPR loss: 0.4553766782310763\n",
      "Iteration: 46, BPR loss: 0.4469346870703506\n",
      "Iteration: 47, BPR loss: 0.44043612237528734\n",
      "Iteration: 48, BPR loss: 0.43526084358268974\n",
      "Iteration: 49, BPR loss: 0.4250404286256464\n",
      "Iteration: 50, BPR loss: 0.4167407047179351\n"
     ]
    }
   ],
   "source": [
    "model2.fit(train2, k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6389e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.17938741721854304\n",
      "Recall@10: 0.053519123145847634\n",
      "NDCG@10: 0.7556304364511268\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "rec, pre, ndcg = model2.performance(test2, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
