{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f0900197",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "f0900197",
        "outputId": "2de226ad-e62e-40c0-ed88-087b3cb1d8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Jester-jokes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Jester-jokes')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce33bdf0",
      "metadata": {
        "id": "ce33bdf0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from Dataset import DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c666ec5c",
      "metadata": {
        "id": "c666ec5c"
      },
      "outputs": [],
      "source": [
        "class BPR(nn.Module, DataSet):\n",
        "    def __init__(self):\n",
        "        super(BPR, self).__init__()\n",
        "        self.rawdf = None\n",
        "\n",
        "        self.W = None             # user matrix\n",
        "        self.H = None             # item matrix\n",
        "        self.Wsc = None           # scorer\n",
        "        self.Hsc = None\n",
        "\n",
        "        self.uid = None\n",
        "        self.iid = None\n",
        "\n",
        "        self.user_items = {}\n",
        "        self.dev_user_items = {}\n",
        "\n",
        "        self.rating_exp = None   # softmax sum\n",
        "        self.rating_exp_mul_H = None\n",
        "\n",
        "    def preprocess(self, train_size=0.7, test_size=0.1):\n",
        "        self.rawdf = pd.read_excel(\"./FINAL jester 2006-15.xlsx\", header=None, usecols=\"B:EU\", names=[i for i in range(150)])\n",
        "        self.rawdf = self.rawdf[self.rawdf != 99]\n",
        "\n",
        "        self.uid = np.asarray([i for i in range(self.rawdf.shape[0])])\n",
        "        self.iid = np.asarray([i for i in range(self.rawdf.shape[1])])\n",
        "\n",
        "        data = self.rawdf.apply(lambda x: x.dropna().index.tolist(), axis=1).tolist()\n",
        "\n",
        "        train_val_set, test_set = self.split_data_randomly(data, test_ratio=test_size)\n",
        "        train_set, val_set = self.split_data_randomly(train_val_set, test_ratio=1-train_size/(1-test_size))\n",
        "\n",
        "        return train_set, val_set, test_set\n",
        "\n",
        "    def generate_train_batch(self, batch, sets):\n",
        "        train = []\n",
        "        for b in range(batch):\n",
        "            u = self.uid[np.random.randint(0, len(self.uid))]\n",
        "            i = sets[u][np.random.randint(0, len(sets[u]))]\n",
        "            j = self.iid[np.random.randint(0, len(self.iid))]\n",
        "            while j in sets[u]:\n",
        "                j = self.iid[np.random.randint(0, len(self.iid))]\n",
        "            train.append([u, i, j])\n",
        "        return np.asarray(train)\n",
        "\n",
        "    def forward(self, uids, iids, device):\n",
        "        self.rating_exp = torch.zeros(len(self.uid)).to(device)\n",
        "        self.rating_exp_mul_H = torch.zeros([len(self.uid), self.H.shape[1]]).to(device)\n",
        "\n",
        "        # 处理 idx 得到 embedded Wu Hi\n",
        "        emb_idxs = [self.user_items[uid] for uid in uids]\n",
        "        item_emb = nn.utils.rnn.pad_sequence([self.Hsc[emb_idx] for emb_idx in emb_idxs], batch_first=True)\n",
        "        user_emb = self.Wsc[uids][:, None, :]\n",
        "\n",
        "        # 计算批次内 user_item 得分\n",
        "        user_item_exp_sc = torch.sum(item_emb * user_emb, dim = -1)\n",
        "        max_sc_per_row = torch.max(user_item_exp_sc, 1).values\n",
        "\n",
        "        mask = (user_item_exp_sc != 0).type(torch.float32)\n",
        "        user_item_exp_sc = user_item_exp_sc - max_sc_per_row[:, None]\n",
        "\n",
        "        # 取指数， mask 保证补 0 位还是 0\n",
        "        user_item_exp_sc = torch.exp(user_item_exp_sc) * mask\n",
        "\n",
        "        # 计算指数和\n",
        "        self.rating_exp_mul_H[uids] = torch.sum(user_item_exp_sc.unsqueeze(2).repeat(1, 1, self.H.shape[1]) * item_emb, dim = 1)\n",
        "        self.rating_exp[uids] = torch.sum(user_item_exp_sc, dim = 1)\n",
        "\n",
        "        #返回 softmax probablilty of item i among user_items\n",
        "        return torch.exp(torch.sum(self.Wsc[uids] * self.Hsc[iids], dim = 1) - max_sc_per_row) / self.rating_exp[uids]\n",
        "\n",
        "    def fit_dds(self, df, dev, k, stepsize=0.1, max_iter=10, batch=10000, dev_batch=5000, score_stepsize=0.1):\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(device)\n",
        "\n",
        "        # 初始化 W，H\n",
        "        self.W = nn.Parameter(torch.rand(len(self.uid), k).to(device) * 0.01)\n",
        "        self.H = nn.Parameter(torch.rand(len(self.iid), k).to(device) * 0.01)\n",
        "\n",
        "        # 初始化 scorer\n",
        "        self.Wsc = torch.rand(len(self.uid), k).to(device) * 0.01\n",
        "        self.Hsc = torch.rand(len(self.iid), k).to(device) * 0.01\n",
        "        # 创建字典：用户u对应他访问过的所有items集合\n",
        "        self.user_items = dict(zip(self.uid, df))\n",
        "        self.dev_user_items = dict(zip(self.uid, dev))\n",
        "\n",
        "        # 主模型优化器\n",
        "        optimizer = optim.SGD([self.W, self.H], lr=stepsize)\n",
        "        # with torch.autograd.detect_anomaly():\n",
        "        for x in range(max_iter):\n",
        "            #取训练批次：uij三元组\n",
        "            uij = self.generate_train_batch(batch, self.user_items)\n",
        "            u = uij[:, 0]\n",
        "            i = uij[:, 1]\n",
        "            j = uij[:, 2]\n",
        "            u_emb = self.W[u]\n",
        "            i_emb = self.H[i]\n",
        "            j_emb = self.H[j]\n",
        "\n",
        "            # 主模型参数更新\n",
        "            score_prob = self.forward(u, i, device)\n",
        "            optimizer.zero_grad()\n",
        "            score_loss = -torch.sum(score_prob * torch.log(torch.sigmoid( torch.sum(u_emb * (i_emb - j_emb),dim = 1) ) ))\n",
        "            bpr_loss = -torch.mean(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
        "            score_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 训练集上 W,H 的梯度\n",
        "            W_grad_sum = self.W.grad.clone()\n",
        "            H_grad_sum = self.H.grad.clone()\n",
        "\n",
        "            # 对数概率分布下 Wsc, Hsc 梯度\n",
        "            log_prob_Wsc_grad = torch.zeros((len(self.uid), k)).to(device)\n",
        "            log_prob_Hsc_grad = torch.zeros((len(self.iid), k)).to(device)\n",
        "            log_prob_Wsc_grad[u] = self.Hsc[i] - self.rating_exp_mul_H[u] / self.rating_exp[u].unsqueeze(1).repeat(1, k)\n",
        "            log_prob_Hsc_grad[i] = self.Wsc[u] * ((1 - score_prob).unsqueeze(1).repeat(1, k))\n",
        "\n",
        "            #取 dev uij三元组\n",
        "            uij = self.generate_train_batch(dev_batch, self.dev_user_items)\n",
        "            u = uij[:, 0]\n",
        "            i = uij[:, 1]\n",
        "            j = uij[:, 2]\n",
        "            u_emb = self.W[u]\n",
        "            i_emb = self.H[i]\n",
        "            j_emb = self.H[j]\n",
        "\n",
        "            # 计算 dev 集上 W,H 的梯度\n",
        "            optimizer.zero_grad()\n",
        "            dev_loss = -torch.sum(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
        "            dev_loss.backward()\n",
        "            W_grad_dev_sum = self.W.grad.clone()\n",
        "            H_grad_dev_sum = self.H.grad.clone()\n",
        "\n",
        "            # 计算 reward: reward 为 W,H 在训练集和 dev 集上的梯度积\n",
        "            r_W = torch.sum(W_grad_sum * W_grad_dev_sum, dim=1)\n",
        "            r_H = torch.sum(H_grad_sum * H_grad_dev_sum, dim=1)\n",
        "            r_W = r_W.unsqueeze(1).repeat(1, k)\n",
        "            r_H = r_H.unsqueeze(1).repeat(1, k)\n",
        "\n",
        "            # Wsc，Hsc 更新\n",
        "            self.Wsc += score_stepsize * r_W * log_prob_Wsc_grad\n",
        "            self.Hsc += score_stepsize * r_H * log_prob_Hsc_grad\n",
        "\n",
        "            if ( x + 1 ) % 10 == 0:\n",
        "                print(f\"Iteration: {x+1}, BPR loss: {bpr_loss.item()}\")\n",
        "\n",
        "\n",
        "    def fit_ori(self, df, k, stepsize=0.05, max_iter=10, batch=10000):\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(device)\n",
        "\n",
        "        self.W = nn.Parameter(torch.rand(len(self.uid), k).to(device) * 0.01)    # 初始化 W，H\n",
        "        self.H = nn.Parameter(torch.rand(len(self.iid), k).to(device) * 0.01)\n",
        "\n",
        "        # 创建字典：用户u对应他访问过的所有items集合\n",
        "        self.user_items = dict(zip(self.uid, df))\n",
        "\n",
        "        optimizer = optim.SGD([self.W, self.H], lr=stepsize)     # 主模型优化器\n",
        "        for x in range(max_iter):\n",
        "            #取训练批次：uij三元组\n",
        "            uij = self.generate_train_batch(batch, self.user_items)\n",
        "\n",
        "            u = uij[:, 0]\n",
        "            i = uij[:, 1]\n",
        "            j = uij[:, 2]\n",
        "            u_emb = self.W[u]\n",
        "            i_emb = self.H[i]\n",
        "            j_emb = self.H[j]\n",
        "            optimizer.zero_grad()\n",
        "            loss = -torch.sum(torch.log(torch.sigmoid(torch.sum(u_emb * (i_emb - j_emb),dim = 1))))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if ( x + 1 ) % 10 == 0:\n",
        "                print(f\"Iteration: {x+1}, BPR loss: {loss.item() / batch}\")\n",
        "\n",
        "    def _predict(self, uid, items, n):\n",
        "        scores = torch.mv(self.H[items], self.W[uid])\n",
        "        if n > scores.shape[0]:\n",
        "            n = scores.shape[0]\n",
        "        top_N_val, top_N_idx = torch.topk(scores, k=n)\n",
        "        return list(zip(items[top_N_idx.cpu()], top_N_val.cpu()))\n",
        "\n",
        "    def NDCG(self, uid, test, n):         # 用模型排序+真实分数计算 DCG, 重排后计算 iDCG\n",
        "        test_user = np.asarray(test[uid])\n",
        "        rating = self._predict(uid, test_user, n)\n",
        "        irating =sorted(self.rawdf.iloc[uid, test_user].to_list(), reverse=True)\n",
        "\n",
        "        dcg = 0\n",
        "        idcg = 0\n",
        "        if n > len(irating): n = len(irating)\n",
        "        for i in range(n):\n",
        "            r = self.rawdf.iloc[uid, rating[i][0]]\n",
        "            dcg += 1.0 * (2**r - 1) / math.log(i + 2, 2)\n",
        "            idcg += 1.0 * (2**irating[i] - 1) / math.log(i + 2, 2)\n",
        "        if idcg==0:\n",
        "            return 0\n",
        "        return dcg / idcg\n",
        "\n",
        "    def performance(self, test, n):      # Output recall@n, precision@n, NDCG@n\n",
        "        hit = 0\n",
        "        n_recall = 0\n",
        "        n_precision = 0\n",
        "        ndcg = 0\n",
        "        for i in self.uid:\n",
        "            # Items that User i hasn't tried in training set\n",
        "            unknown_items = np.setdiff1d(self.iid, self.user_items[i])\n",
        "            # Items that User i actually tried in testing set\n",
        "            known_items = test[i]\n",
        "\n",
        "            #目标：预测 unknown items 中的top_N，若击中test中的items，则为有效预测\n",
        "            ru = self._predict(i, unknown_items, n)\n",
        "\n",
        "            hit += sum(1 for item, pui in ru if item in known_items)\n",
        "            n_recall += len(known_items)\n",
        "            n_precision += n\n",
        "            ndcg += self.NDCG(i, test, n)\n",
        "\n",
        "        recall = hit / (1.0 * n_recall)\n",
        "        precision = hit / (1.0 * n_precision)\n",
        "        ndcg /= len(self.uid)\n",
        "        return recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "da1781ca",
      "metadata": {
        "scrolled": true,
        "id": "da1781ca"
      },
      "outputs": [],
      "source": [
        "model1 = BPR()\n",
        "train1, test1, dev1 = model1.preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a055d2a",
      "metadata": {
        "id": "5a055d2a"
      },
      "source": [
        "### Pure BPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26dbdb06",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26dbdb06",
        "outputId": "964ac1d0-4d66-4825-84d9-2c2ac90d9a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 10, BPR loss: 0.610598876953125\n",
            "Iteration: 20, BPR loss: 0.41485166015625\n",
            "Iteration: 30, BPR loss: 0.3443927001953125\n",
            "Iteration: 40, BPR loss: 0.3110560791015625\n",
            "Iteration: 50, BPR loss: 0.29342548828125\n",
            "Iteration: 60, BPR loss: 0.281359619140625\n",
            "Iteration: 70, BPR loss: 0.27257861328125\n",
            "Iteration: 80, BPR loss: 0.268765380859375\n",
            "Iteration: 90, BPR loss: 0.263113916015625\n",
            "Iteration: 100, BPR loss: 0.24789072265625\n",
            "Iteration: 110, BPR loss: 0.2594363525390625\n",
            "Iteration: 120, BPR loss: 0.262428759765625\n",
            "Iteration: 130, BPR loss: 0.244652099609375\n",
            "Iteration: 140, BPR loss: 0.25047158203125\n",
            "Iteration: 150, BPR loss: 0.2465968505859375\n",
            "Iteration: 160, BPR loss: 0.244673779296875\n",
            "Iteration: 170, BPR loss: 0.235258984375\n",
            "Iteration: 180, BPR loss: 0.231139013671875\n",
            "Iteration: 190, BPR loss: 0.244002783203125\n",
            "Iteration: 200, BPR loss: 0.243602099609375\n",
            "Iteration: 210, BPR loss: 0.240953466796875\n",
            "Iteration: 220, BPR loss: 0.2280675537109375\n",
            "Iteration: 230, BPR loss: 0.2282104736328125\n",
            "Iteration: 240, BPR loss: 0.23140927734375\n",
            "Iteration: 250, BPR loss: 0.2211328857421875\n",
            "Iteration: 260, BPR loss: 0.2202962890625\n",
            "Iteration: 270, BPR loss: 0.2202334228515625\n",
            "Iteration: 280, BPR loss: 0.220115087890625\n",
            "Iteration: 290, BPR loss: 0.2084778564453125\n",
            "Iteration: 300, BPR loss: 0.223268310546875\n",
            "Iteration: 310, BPR loss: 0.216666015625\n",
            "Iteration: 320, BPR loss: 0.2055435546875\n",
            "Iteration: 330, BPR loss: 0.210159326171875\n",
            "Iteration: 340, BPR loss: 0.20481103515625\n",
            "Iteration: 350, BPR loss: 0.20295469970703126\n",
            "Iteration: 360, BPR loss: 0.2079984619140625\n",
            "Iteration: 370, BPR loss: 0.20076258544921874\n",
            "Iteration: 380, BPR loss: 0.188986328125\n",
            "Iteration: 390, BPR loss: 0.19107620849609375\n",
            "Iteration: 400, BPR loss: 0.19503211669921874\n",
            "Iteration: 410, BPR loss: 0.1873506103515625\n",
            "Iteration: 420, BPR loss: 0.17540396728515625\n",
            "Iteration: 430, BPR loss: 0.17595474853515625\n",
            "Iteration: 440, BPR loss: 0.179799609375\n",
            "Iteration: 450, BPR loss: 0.17939141845703124\n",
            "Iteration: 460, BPR loss: 0.1717220703125\n",
            "Iteration: 470, BPR loss: 0.1726481689453125\n",
            "Iteration: 480, BPR loss: 0.17313240966796875\n",
            "Iteration: 490, BPR loss: 0.1651913330078125\n",
            "Iteration: 500, BPR loss: 0.1608088134765625\n",
            "CPU times: user 1min 12s, sys: 899 ms, total: 1min 13s\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model1.fit_ori(train1, k = 20, max_iter = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85461f8d",
      "metadata": {
        "id": "85461f8d",
        "outputId": "3b62df43-ee3f-4b76-8931-751879f8c06c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.2720207631363264\n",
            "Recall@10: 0.3780753604111028\n",
            "NDCG@10: 0.6889992358777942\n",
            "CPU times: user 1min 6s, sys: 410 ms, total: 1min 6s\n",
            "Wall time: 1min 9s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "n = 10\n",
        "rec, pre, ndcg = model1.performance(test1, n)\n",
        "print(f'Precision@{n}: {pre}')\n",
        "print(f'Recall@{n}: {rec}')\n",
        "print(f'NDCG@{n}: {ndcg}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a41f9423",
      "metadata": {
        "id": "a41f9423"
      },
      "source": [
        "### BPR + Data Selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model1.fit_dds(train1, dev1, k = 20, max_iter = 500, score_stepsize=0.1, stepsize=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJWonMK4IS3N",
        "outputId": "bad2db25-da25-4c23-9e52-42297061db87"
      },
      "id": "rJWonMK4IS3N",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 10, BPR loss: 0.47072479128837585\n",
            "Iteration: 20, BPR loss: 0.36783748865127563\n",
            "Iteration: 30, BPR loss: 0.31012463569641113\n",
            "Iteration: 40, BPR loss: 0.29375311732292175\n",
            "Iteration: 50, BPR loss: 0.27312150597572327\n",
            "Iteration: 60, BPR loss: 0.2647259831428528\n",
            "Iteration: 70, BPR loss: 0.2651131749153137\n",
            "Iteration: 80, BPR loss: 0.2621009349822998\n",
            "Iteration: 90, BPR loss: 0.2619037926197052\n",
            "Iteration: 100, BPR loss: 0.2602253258228302\n",
            "Iteration: 110, BPR loss: 0.25641772150993347\n",
            "Iteration: 120, BPR loss: 0.23983149230480194\n",
            "Iteration: 130, BPR loss: 0.2519305944442749\n",
            "Iteration: 140, BPR loss: 0.25606396794319153\n",
            "Iteration: 150, BPR loss: 0.2468380481004715\n",
            "Iteration: 160, BPR loss: 0.2396354228258133\n",
            "Iteration: 170, BPR loss: 0.23802855610847473\n",
            "Iteration: 180, BPR loss: 0.24400494992733002\n",
            "Iteration: 190, BPR loss: 0.24050316214561462\n",
            "Iteration: 200, BPR loss: 0.2450360804796219\n",
            "Iteration: 210, BPR loss: 0.23917467892169952\n",
            "Iteration: 220, BPR loss: 0.226120263338089\n",
            "Iteration: 230, BPR loss: 0.23183664679527283\n",
            "Iteration: 240, BPR loss: 0.2210749387741089\n",
            "Iteration: 250, BPR loss: 0.2226000875234604\n",
            "Iteration: 260, BPR loss: 0.21758314967155457\n",
            "Iteration: 270, BPR loss: 0.21665871143341064\n",
            "Iteration: 280, BPR loss: 0.21043075621128082\n",
            "Iteration: 290, BPR loss: 0.19712311029434204\n",
            "Iteration: 300, BPR loss: 0.19875755906105042\n",
            "Iteration: 310, BPR loss: 0.19951285421848297\n",
            "Iteration: 320, BPR loss: 0.19739580154418945\n",
            "Iteration: 330, BPR loss: 0.18304981291294098\n",
            "Iteration: 340, BPR loss: 0.183933287858963\n",
            "Iteration: 350, BPR loss: 0.18762315809726715\n",
            "Iteration: 360, BPR loss: 0.1821761578321457\n",
            "Iteration: 370, BPR loss: 0.17486242949962616\n",
            "Iteration: 380, BPR loss: 0.18226510286331177\n",
            "Iteration: 390, BPR loss: 0.17716559767723083\n",
            "Iteration: 400, BPR loss: 0.16923421621322632\n",
            "Iteration: 410, BPR loss: 0.16341760754585266\n",
            "Iteration: 420, BPR loss: 0.1600194126367569\n",
            "Iteration: 430, BPR loss: 0.16209439933300018\n",
            "Iteration: 440, BPR loss: 0.1622907966375351\n",
            "Iteration: 450, BPR loss: 0.1666717380285263\n",
            "Iteration: 460, BPR loss: 0.15748263895511627\n",
            "Iteration: 470, BPR loss: 0.15159589052200317\n",
            "Iteration: 480, BPR loss: 0.14915966987609863\n",
            "Iteration: 490, BPR loss: 0.15078598260879517\n",
            "Iteration: 500, BPR loss: 0.1474992334842682\n",
            "CPU times: user 6min 29s, sys: 837 ms, total: 6min 30s\n",
            "Wall time: 6min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "n = 10\n",
        "rec, pre, ndcg = model1.performance(test1, n)\n",
        "print(f'Precision@{n}: {pre}')\n",
        "print(f'Recall@{n}: {rec}')\n",
        "print(f'NDCG@{n}: {ndcg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8QEm59RIgLg",
        "outputId": "40fed7b9-3e49-4dc7-f338-ceea4fd1395e"
      },
      "id": "X8QEm59RIgLg",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.27510791366906473\n",
            "Recall@10: 0.38236611945776955\n",
            "NDCG@10: 0.7010044041956096\n",
            "CPU times: user 1min 6s, sys: 155 ms, total: 1min 6s\n",
            "Wall time: 1min 7s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}