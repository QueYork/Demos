{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce33bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39548858",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptimizer(optim.Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr):\n",
    "        self.lr = lr\n",
    "        super(MyOptimizer, self).__init__(params, {})\n",
    "\n",
    "    def step(self, scorer, closure=False):\n",
    "        for param_group in self.param_groups:\n",
    "            params = param_group['params']\n",
    "            # 从param_group中拿出参数\n",
    "            for param in params:\n",
    "                # 循环更新每一个参数的值\n",
    "                param.data = param.data - self.lr * scorer * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c666ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPR, self).__init__()\n",
    "        \n",
    "        self.W = None             # user matrix\n",
    "        self.H = None             # item matrix\n",
    "        \n",
    "        self.Wsc = None        # scorer\n",
    "        self.Hsc = None \n",
    "        \n",
    "        self.rating_exp = {}\n",
    "        self.rating_exp_mul_H = {}\n",
    "        \n",
    "        self.user_items = {}\n",
    "        self.dev_user_items = {}\n",
    "        \n",
    "        self.uid = None\n",
    "        self.iid = None\n",
    "        \n",
    "        self.uid_dict = None      # serialize uid and iid\n",
    "        self.iid_dict = None      #  {(original id in dataset): (serial_idx)}\n",
    "        self.uid_dict_rev = None  # reverse key and value\n",
    "        self.iid_dict_rev = None  #  {(serial_idx): (original id in dataset)}\n",
    "        \n",
    "    def _split(self, df, ratio):\n",
    "        train = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        test = pd.DataFrame(columns = df.columns, dtype=int)\n",
    "        for i in self.uid:\n",
    "            train_1, test_1 = train_test_split(df[df.iloc[:, 0] == i], train_size = ratio, shuffle = True, random_state = 5)\n",
    "            train = pd.concat([train, train_1])\n",
    "            test = pd.concat([test, test_1])\n",
    "        return train, test\n",
    "    \n",
    "    def split(self, df, train_size=0.8, test_size=0.1):\n",
    "        self.uid = np.asarray(list(set(df.iloc[:,0].values)))\n",
    "        self.iid = np.asarray(list(set(df.iloc[:,1].values)))\n",
    "        self.uid.sort()\n",
    "        self.iid.sort()\n",
    "        self.uid_dict = dict(zip(self.uid, [i for i in range(len(self.uid))]))\n",
    "        self.iid_dict = dict(zip(self.iid, [i for i in range(len(self.iid))]))\n",
    "        self.uid_dict_rev = {v: k for k, v in self.uid_dict.items()}\n",
    "        self.iid_dict_rev = {v: k for k, v in self.iid_dict.items()}\n",
    "        \n",
    "        train, test = self._split(df, train_size)\n",
    "        test, dev = self._split(test, test_size / (1 - train_size))\n",
    "        \n",
    "        return train, test, dev\n",
    "    \n",
    "    def generate_train_batch(self, batch, sets):\n",
    "        train = []\n",
    "        for b in range(batch):\n",
    "            u = self.uid[np.random.randint(0, len(self.uid))]\n",
    "            i = sets[u][np.random.randint(0, len(sets[u]))]\n",
    "            j = self.iid[np.random.randint(0, len(self.iid))]\n",
    "            while j in sets[u]:\n",
    "                j = self.iid[np.random.randint(0, len(self.iid))]\n",
    "            train.append([self.uid_dict[u], self.iid_dict[i], self.iid_dict[j]])\n",
    "        return np.asarray(train) \n",
    "    \n",
    "    def scorer_prob(self, uid, iid):              # Softmax probability, uids, iids serial\n",
    "        if uid not in self.rating_exp.keys():\n",
    "            r = 0\n",
    "            h = 0\n",
    "            for i in self.user_items[self.uid_dict_rev[uid]]:\n",
    "                temp = torch.exp(torch.dot(self.Wsc[uid], self.Hsc[self.iid_dict[i]]))\n",
    "                r += temp\n",
    "                h += temp * self.Hsc[self.iid_dict[i]]\n",
    "            self.rating_exp[uid] = r\n",
    "            self.rating_exp_mul_H[uid] = h\n",
    "        return torch.exp(torch.dot(self.Wsc[uid], self.Hsc[iid])) / self.rating_exp[uid]\n",
    "\n",
    "    def fit_dds(self, df, dev, k, stepsize=0.05, regulation_rate=0.0001, max_iter=10, batch=10000):\n",
    "        self.W = nn.Parameter(torch.rand(len(self.uid), k) * 0.01)    # 初始化 W，H\n",
    "        self.H = nn.Parameter(torch.rand(len(self.iid), k) * 0.01)  \n",
    "        \n",
    "        self.Wsc = torch.rand(len(self.uid), k) * 0.01  # 初始化 scorer\n",
    "        self.Hsc = torch.rand(len(self.iid), k) * 0.01\n",
    "\n",
    "        for u in self.uid:                                # 创建字典：用户u对应他访问过的所有items集合\n",
    "            self.user_items[u] = df[df.iloc[:, 0]==u].iloc[:, 1].values\n",
    "            self.dev_user_items[u] = dev[dev.iloc[:, 0]==u].iloc[:, 1].values     \n",
    "        \n",
    "        optimizer = MyOptimizer([self.W, self.H], lr=1)\n",
    "\n",
    "        for x in range(max_iter):\n",
    "            \n",
    "            # Model update\n",
    "            loss_sum = 0\n",
    "            W_grad_sum = torch.zeros(len(self.uid), k)\n",
    "            H_grad_sum = torch.zeros(len(self.iid), k)\n",
    "            \n",
    "            uij = self.generate_train_batch(batch, self.user_items)\n",
    "            \n",
    "            for u, i, j in uij:\n",
    "                optimizer.zero_grad()\n",
    "                loss = -torch.log(torch.sigmoid(torch.sum(self.W[u] * (self.H[i] - self.H[j]))))\n",
    "                loss.backward()\n",
    "                \n",
    "                W_grad_sum += self.W.grad\n",
    "                H_grad_sum += self.H.grad\n",
    "            \n",
    "                optimizer.step(scorer = self.scorer_prob(u, i))\n",
    "                loss_sum += loss\n",
    "\n",
    "            # DDS update\n",
    "            W_grad_dev_sum = torch.zeros(len(self.uid), k)\n",
    "            H_grad_dev_sum = torch.zeros(len(self.iid), k)\n",
    "\n",
    "            for u, i, j in self.generate_train_batch(5000, self.dev_user_items):\n",
    "                optimizer.zero_grad()\n",
    "                dev_loss = -torch.log(torch.sigmoid(torch.sum(self.W[u] * (self.H[i] - self.H[j]))))\n",
    "                dev_loss.backward()\n",
    "            \n",
    "                W_grad_dev_sum += self.W.grad\n",
    "                H_grad_dev_sum += self.H.grad\n",
    "                \n",
    "            r_W = torch.sum(W_grad_sum * W_grad_dev_sum, dim=1)\n",
    "            r_H = torch.sum(H_grad_sum * H_grad_dev_sum, dim=1)\n",
    "            r_W = r_W.unsqueeze(1).repeat(1, k)\n",
    "            r_H = r_H.unsqueeze(1).repeat(1, k)\n",
    "\n",
    "            log_prob_W_grad_sum = torch.zeros(len(self.uid), k)\n",
    "            log_prob_H_grad_sum = torch.zeros(len(self.iid), k)\n",
    "\n",
    "            for u, i, j in uij:               \n",
    "                log_prob_W_grad_sum[u] = self.Hsc[i] - self.rating_exp_mul_H[u] / self.rating_exp[u]\n",
    "                log_prob_H_grad_sum[i] = self.Wsc[u] * (1 - self.scorer_prob(u, i))\n",
    "\n",
    "            self.Wsc += r_W * log_prob_W_grad_sum\n",
    "            self.Hsc += r_H * log_prob_H_grad_sum\n",
    "\n",
    "            self.rating_exp = {}\n",
    "            self.rating_exp_mul_H = {}\n",
    "\n",
    "#             if x == max_iter - 1:\n",
    "            print(f\"Iteration: {x+1}, BPR loss: {loss_sum.item() / batch}\")\n",
    "                \n",
    "    def _predict(self, uid, items, n):\n",
    "        top_N = []\n",
    "\n",
    "        for i in range(len(items)):\n",
    "            user = self.uid_dict[uid]\n",
    "            item = self.iid_dict[items[i]]\n",
    "            top_N.append((items[i], torch.dot(self.W[user], self.H[item])))\n",
    "\n",
    "        return sorted(top_N, key=lambda s: s[1], reverse=True)[:n]\n",
    "\n",
    "    def NDCG(self, uid, test, n):\n",
    "        test_user = test[test[:, 0] == uid]\n",
    "        rating = self._predict(uid, test_user[:, 1], n)\n",
    "        irating = sorted(test_user[:, 2], reverse=True)\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        if n > len(irating):\n",
    "            n = len(irating)\n",
    "        for i in range(n):\n",
    "            r = test_user[test_user[:, 1] == rating[i][0], 2][0]\n",
    "            dcg += 1.0 * (2 ** r - 1) / math.log(i + 2, 2)\n",
    "            idcg += 1.0 * (2 ** irating[i] - 1) / math.log(i + 2, 2)\n",
    "        return dcg / idcg\n",
    "\n",
    "    def performance(self, test, n):\n",
    "        hit = 0\n",
    "        n_recall = 0\n",
    "        n_precision = 0\n",
    "        ndcg = 0\n",
    "        for i in self.uid:\n",
    "            unknown_items = np.setdiff1d(self.iid, self.user_items[i])\n",
    "            known_items = test[test[:, 0] == i][:, 1]\n",
    "\n",
    "            ru = self._predict(i, unknown_items, n)\n",
    "            for item, pui in ru:\n",
    "                if item in known_items:\n",
    "                    hit += 1\n",
    "            n_recall += len(known_items)\n",
    "            n_precision += n\n",
    "            ndcg += self.NDCG(i, test, n)\n",
    "\n",
    "        recall = hit / (1.0 * n_recall)\n",
    "        precision = hit / (1.0 * n_precision)\n",
    "        ndcg /= len(self.uid)\n",
    "        return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319ffcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./ml-100k/u.data\", sep=\"\\t\", names=['user id', 'item id', 'rating', 'timestamp'])\n",
    "df2 = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", names=['user id', 'item id', 'rating', 'timestamp'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2cdfb1",
   "metadata": {},
   "source": [
    "### 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da1781ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79619, 4)\n",
      "(9942, 4)\n",
      "(10439, 4)\n"
     ]
    }
   ],
   "source": [
    "model1 = BPR()\n",
    "train1, test1, dev1 = model1.split(df1)\n",
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(dev1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "800fb014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, BPR loss: 0.693035498046875\n",
      "Iteration: 2, BPR loss: 0.692777587890625\n",
      "Iteration: 3, BPR loss: 0.692345263671875\n",
      "Iteration: 4, BPR loss: 0.6914646484375\n",
      "Iteration: 5, BPR loss: 0.689738916015625\n",
      "Iteration: 6, BPR loss: 0.68580107421875\n",
      "Iteration: 7, BPR loss: 0.67814130859375\n",
      "Iteration: 8, BPR loss: nan\n",
      "Iteration: 9, BPR loss: nan\n",
      "Iteration: 10, BPR loss: nan\n",
      "CPU times: total: 2min 17s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit_dds(train1, dev1, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b0edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.13626723223753975\n",
      "Recall@10: 0.1292496479581573\n",
      "NDCG@10: 0.8197595966855103\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "rec, pre, ndcg = model1.performance(test1, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271c144c",
   "metadata": {},
   "source": [
    "### 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23925bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797758, 4)\n",
      "(99692, 4)\n",
      "(102759, 4)\n"
     ]
    }
   ],
   "source": [
    "model3 = BPR()\n",
    "model4 = BPR()\n",
    "train3, test3, dev3 = model3.split(df2)\n",
    "train4, test4, dev4 = model4.split(df2)\n",
    "print(train3.shape)\n",
    "print(test3.shape)\n",
    "print(dev3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81b6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, BPR loss: 0.1950905779539366\n"
     ]
    }
   ],
   "source": [
    "model3.fit_normal(train3, k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90fedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.13279801324503313\n",
      "Recall@10: 0.08045781005496931\n",
      "NDCG@10: 0.8144240583321367\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "rec, pre, ndcg = model3.performance(test3, n)\n",
    "print(f'Precision@{n}: {pre}')\n",
    "print(f'Recall@{n}: {rec}')\n",
    "print(f'NDCG@{n}: {ndcg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
